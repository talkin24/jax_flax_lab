{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2mlvfseGvwEwausRxiDZj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talkin24/jaxflax_lab/blob/main/Flax_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_876emofoNDq",
        "outputId": "3cdf70b0-e7bc-40dd-cd8f-f00342ffa547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/2.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for flax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install the latest JAXlib version.\n",
        "!pip install --upgrade -q pip jax jaxlib\n",
        "# Install Flax at head:\n",
        "!pip install --upgrade -q git+https://github.com/google/flax.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "from typing import Any, Callable, Sequence\n",
        "from jax import lax, random, numpy as jnp\n",
        "from flax.core import freeze, unfreeze\n",
        "from flax import linen as nn"
      ],
      "metadata": {
        "id": "h_q1NtOpqEEd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We create one dense layer instance (taking 'features' parameter as input)\n",
        "model = nn.Dense(features=5)"
      ],
      "metadata": {
        "id": "XNDwdmtnqGuz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "출력만 입력하면 됨"
      ],
      "metadata": {
        "id": "tAkxggqluHaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Parameters & initialization\n",
        "\n",
        "- 파라미터는 모델에 저장되지 않음. init 함수를 호출하여 초기화해주어야 함. 이때 PRNGKey와 더미 인풋을 사용함."
      ],
      "metadata": {
        "id": "b_A2RrtYqj1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key1, key2 = random.split(random.PRNGKey(0))\n",
        "x = random.normal(key1, (10,)) # Dummy input data\n",
        "params = model.init(key2, x) # Initialization call\n",
        "jax.tree_util.tree_map(lambda x: x.shape, params) # Checking output shapes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdv2i8ikqT8m",
        "outputId": "93c73a18-fbaf-42a4-aa7d-115117d11d0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    params: {\n",
              "        bias: (5,),\n",
              "        kernel: (10, 5),\n",
              "    },\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- JAX/FLAX는 numpy처럼 row-based 시스템. 벡터는 행 벡터 기준임\n",
        "\n",
        "- `init_with_output` 메소드로 더미 인풋의 forward pass 출력도 함께 리턴 가능\n",
        "\n",
        "- 출력은 FrozenDict 인스턴스로 저장됨. 이는 immutable하며 사용자가 이를 인식하게 도와줌.\n",
        "\n"
      ],
      "metadata": {
        "id": "WZCmbEu3rNAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    params['new_key'] = jnp.ones((2,2))\n",
        "except ValueError as e:\n",
        "    print(\"Error: \", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZVBtEOFqhAJ",
        "outputId": "2420c0ad-1a9e-48e9-9e1f-888f9f50fcda"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:  FrozenDict is immutable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.apply(params, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wAaVOvorK6t",
        "outputId": "50324294-1ad7-419c-c435-8857ec37b980"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([-1.3721193 ,  0.61131495,  0.6442836 ,  2.2192965 , -1.1271116 ],      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set problem dimensions.\n",
        "n_samples = 20\n",
        "x_dim = 10\n",
        "y_dim = 5\n",
        "\n",
        "# Generate random ground truth W and b.\n",
        "key = random.PRNGKey(0)\n",
        "k1, k2 = random.split(key)\n",
        "W = random.normal(k1, (x_dim, y_dim))\n",
        "b = random.normal(k2, (y_dim,))\n",
        "# Store the parameters in a FrozenDict pytree.\n",
        "true_params = freeze({'params': {'bias': b, 'kernel': W}})\n",
        "\n",
        "# Generate samples with additional noise.\n",
        "key_sample, key_noise = random.split(k1)\n",
        "x_samples = random.normal(key_sample, (n_samples, x_dim))\n",
        "y_samples = jnp.dot(x_samples, W) + b + 0.1 * random.normal(key_noise,(n_samples, y_dim))\n",
        "print('x shape:', x_samples.shape, '; y shape:', y_samples.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K09Q9fwxwTsX",
        "outputId": "29058fb4-71e0-4450-a0af-2a485e2fec3a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: (20, 10) ; y shape: (20, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as JAX version but using model.apply().\n",
        "@jax.jit\n",
        "def mse(params, x_batched, y_batched):\n",
        "  # Define the squared loss for a single pair (x,y)\n",
        "  def squared_error(x, y):\n",
        "    pred = model.apply(params, x)\n",
        "    return jnp.inner(y-pred, y-pred) / 2.0\n",
        "  # Vectorize the previous to compute the average of the loss on all samples.\n",
        "  return jnp.mean(jax.vmap(squared_error)(x_batched,y_batched), axis=0)"
      ],
      "metadata": {
        "id": "XNmChSQMxlju"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.3  # Gradient step size.\n",
        "print('Loss for \"true\" W,b: ', mse(true_params, x_samples, y_samples))\n",
        "loss_grad_fn = jax.value_and_grad(mse)\n",
        "\n",
        "@jax.jit\n",
        "def update_params(params, learning_rate, grads):\n",
        "  params = jax.tree_util.tree_map(\n",
        "      lambda p, g: p - learning_rate * g, params, grads)\n",
        "  return params\n",
        "\n",
        "for i in range(101):\n",
        "  # Perform one gradient update.\n",
        "  loss_val, grads = loss_grad_fn(params, x_samples, y_samples)\n",
        "  params = update_params(params, learning_rate, grads)\n",
        "  if i % 10 == 0:\n",
        "    print(f'Loss step {i}: ', loss_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCv-Ij1g1URM",
        "outputId": "816be1cc-5e91-407b-e12a-ce7340313926"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for \"true\" W,b:  0.02363979\n",
            "Loss step 0:  35.343876\n",
            "Loss step 10:  0.5143469\n",
            "Loss step 20:  0.11384159\n",
            "Loss step 30:  0.039326735\n",
            "Loss step 40:  0.019916208\n",
            "Loss step 50:  0.014209135\n",
            "Loss step 60:  0.012425654\n",
            "Loss step 70:  0.01185039\n",
            "Loss step 80:  0.011661784\n",
            "Loss step 90:  0.011599409\n",
            "Loss step 100:  0.011578695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing with Optax\n",
        "\n",
        "- Optax는 스케쥴링(시간에 따라 옵티마이저 파라미터 변경), 마스킹(트리별 다른 파라미터 업데이트)도 지원함"
      ],
      "metadata": {
        "id": "6RorphHh4C9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "tx = optax.adam(learning_rate=learning_rate)\n",
        "opt_state = tx.init(params)\n",
        "loss_grad_fn = jax.value_and_grad(mse)"
      ],
      "metadata": {
        "id": "_Hm5zS_V5pZB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Optimizer state도 설정해주어야 함"
      ],
      "metadata": {
        "id": "Sc2divv2K-f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(101):\n",
        "  loss_val, grads = loss_grad_fn(params, x_samples, y_samples)\n",
        "  updates, opt_state = tx.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  if i % 10 == 0:\n",
        "    print('Loss step {}: '.format(i), loss_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WynIzR36CbY",
        "outputId": "7c29f6ce-415f-42ac-dff2-3140913c1be4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss step 0:  0.011577628\n",
            "Loss step 10:  0.26143155\n",
            "Loss step 20:  0.07675027\n",
            "Loss step 30:  0.03644055\n",
            "Loss step 40:  0.022012806\n",
            "Loss step 50:  0.016178599\n",
            "Loss step 60:  0.0130028\n",
            "Loss step 70:  0.012026141\n",
            "Loss step 80:  0.011764516\n",
            "Loss step 90:  0.0116460435\n",
            "Loss step 100:  0.011585529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`optax.apply_updates`로 업데이트 "
      ],
      "metadata": {
        "id": "7CB5HyeqLX-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serializing the result"
      ],
      "metadata": {
        "id": "g4ti7QiILjiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import serialization\n",
        "bytes_output = serialization.to_bytes(params)\n",
        "dict_output = serialization.to_state_dict(params)\n",
        "print('Dict output')\n",
        "print(dict_output)\n",
        "print('Bytes output')\n",
        "print(bytes_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2R1EXimLu4e",
        "outputId": "80854da4-ec81-4e6a-9734-48a18a2e0408"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dict output\n",
            "{'params': {'bias': Array([-1.4561517, -2.0283859,  2.0785248,  1.2180303, -0.9993835],      dtype=float32), 'kernel': Array([[ 1.009248  ,  0.18867432,  0.04391698, -0.928683  ,  0.34787187],\n",
            "       [ 1.7301217 ,  0.98819846,  1.1643261 ,  1.1008728 , -0.1068265 ],\n",
            "       [-1.2040868 ,  0.28517762,  1.4144661 ,  0.11754218, -1.3146015 ],\n",
            "       [-1.1944853 , -0.18990842,  0.03379964,  1.3166167 ,  0.08113391],\n",
            "       [ 0.13801418,  1.3707805 , -1.319223  ,  0.5310065 , -2.2408094 ],\n",
            "       [ 0.5634556 ,  0.812729  ,  0.31803787,  0.5350531 ,  0.9062198 ],\n",
            "       [-0.37820524,  1.7420965 ,  1.0800813 , -0.5029262 ,  0.9282519 ],\n",
            "       [ 0.96965903, -1.3163381 ,  0.33582455,  0.8089384 , -1.2017919 ],\n",
            "       [ 1.0207036 , -0.6189928 ,  1.0831568 , -1.8377141 , -0.45602012],\n",
            "       [-0.64296687,  0.4573661 , -1.1322317 , -0.6846899 ,  0.16773744]],      dtype=float32)}}\n",
            "Bytes output\n",
            "b'\\x81\\xa6params\\x82\\xa4bias\\xc7!\\x01\\x93\\x91\\x05\\xa7float32\\xc4\\x14.c\\xba\\xbf\\x13\\xd1\\x01\\xc0\\x8d\\x06\\x05@k\\xe8\\x9b?\\x99\\xd7\\x7f\\xbf\\xa6kernel\\xc7\\xd6\\x01\\x93\\x92\\n\\x05\\xa7float32\\xc4\\xc8\\n/\\x81?\\xd73A>K\\xe23=+\\xbem\\xbfC\\x1c\\xb2>\\xa1t\\xdd?\\x93\\xfa|?\\xa3\\x08\\x95?f\\xe9\\x8c?\\xda\\xc7\\xda\\xbd\\x84\\x1f\\x9a\\xbf\\xcd\\x02\\x92>:\\r\\xb5?\\xf4\\xb9\\xf0=\\xddD\\xa8\\xbf\\xe5\\xe4\\x98\\xbfZwB\\xbe}q\\n=\\xe5\\x86\\xa8?\\x89)\\xa6=\\x97S\\r>\\xbcu\\xaf?M\\xdc\\xa8\\xbf\\x0b\\xf0\\x07?li\\x0f\\xc0\\xa0>\\x10?\\x02\\x0fP?\\xdc\\xd5\\xa2>=\\xf9\\x08?\\x05\\xfeg?\\x1e\\xa4\\xc1\\xbe\\x05\\xfd\\xde?\\x1b@\\x8a?\\xc5\\xbf\\x00\\xbf\\xeb\\xa1m?\\x93;x?\\xc4}\\xa8\\xbf2\\xf1\\xab>\\x96\\x16O?Q\\xd4\\x99\\xbfj\\xa6\\x82?Pv\\x1e\\xbf\\xe2\\xa4\\x8a?7:\\xeb\\xbfx{\\xe9\\xbez\\x99$\\xbf\\xe4+\\xea>\\xf8\\xec\\x90\\xbf\\xd6G/\\xbf]\\xc3+>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "serialization.from_bytes(params, bytes_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez2DtRVJLwuX",
        "outputId": "1ea01f79-4ee3-43e4-9806-81441653bb98"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    params: {\n",
              "        bias: array([-1.4561517, -2.0283859,  2.0785248,  1.2180303, -0.9993835],\n",
              "              dtype=float32),\n",
              "        kernel: array([[ 1.009248  ,  0.18867432,  0.04391698, -0.928683  ,  0.34787187],\n",
              "               [ 1.7301217 ,  0.98819846,  1.1643261 ,  1.1008728 , -0.1068265 ],\n",
              "               [-1.2040868 ,  0.28517762,  1.4144661 ,  0.11754218, -1.3146015 ],\n",
              "               [-1.1944853 , -0.18990842,  0.03379964,  1.3166167 ,  0.08113391],\n",
              "               [ 0.13801418,  1.3707805 , -1.319223  ,  0.5310065 , -2.2408094 ],\n",
              "               [ 0.5634556 ,  0.812729  ,  0.31803787,  0.5350531 ,  0.9062198 ],\n",
              "               [-0.37820524,  1.7420965 ,  1.0800813 , -0.5029262 ,  0.9282519 ],\n",
              "               [ 0.96965903, -1.3163381 ,  0.33582455,  0.8089384 , -1.2017919 ],\n",
              "               [ 1.0207036 , -0.6189928 ,  1.0831568 , -1.8377141 , -0.45602012],\n",
              "               [-0.64296687,  0.4573661 , -1.1322317 , -0.6846899 ,  0.16773744]],\n",
              "              dtype=float32),\n",
              "    },\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에 생성된 params을 템플릿으로 활용하여 모델 load"
      ],
      "metadata": {
        "id": "7PRCQUryMEdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining your own models"
      ],
      "metadata": {
        "id": "rjF4PlyeOhfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExplicitMLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "\n",
        "  def setup(self):\n",
        "    # we automatically know what to do with lists, dicts of submodules\n",
        "    self.layers = [nn.Dense(feat) for feat in self.features]\n",
        "    # for single submodules, we would just write:\n",
        "    # self.layer1 = nn.Dense(feat1)\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, lyr in enumerate(self.layers):\n",
        "      x = lyr(x)\n",
        "      if i != len(self.layers) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
        "x = random.uniform(key1, (4,4))\n",
        "\n",
        "model = ExplicitMLP(features=[3,4,5])\n",
        "params = model.init(key2, x)\n",
        "y = model.apply(params, x)\n",
        "\n",
        "print('initialized parameter shapes:\\n', jax.tree_util.tree_map(jnp.shape, unfreeze(params)))\n",
        "print('output:\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDCk1_NrMQDy",
        "outputId": "723b90b7-47a8-49c3-8b7a-e34216caa9c4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialized parameter shapes:\n",
            " {'params': {'layers_0': {'bias': (3,), 'kernel': (4, 3)}, 'layers_1': {'bias': (4,), 'kernel': (3, 4)}, 'layers_2': {'bias': (5,), 'kernel': (4, 5)}}}\n",
            "output:\n",
            " [[ 0.          0.          0.          0.          0.        ]\n",
            " [ 0.0072379  -0.00810348 -0.0255094   0.02151717 -0.01261241]\n",
            " [ 0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`setup()` 메서드는 서브모듈, 변수, 파라미터 등 모델에 필요한 것들을 등록하는 `__postinit__` 다음에 호출됨"
      ],
      "metadata": {
        "id": "PA47iSBbRFWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    y = model(x) # Returns an error\n",
        "except AttributeError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvlmJzjRMYgI",
        "outputId": "2f3c5edb-96d8-402d-f018-35e5ddf47a79"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"ExplicitMLP\" object has no attribute \"layers\". If \"layers\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 구조와 파라미터가 직접 연결되어 있지 않으므로 바로 `model(x)`를 call 할 수 없음"
      ],
      "metadata": {
        "id": "w_BPv48gQtsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, feat in enumerate(self.features):\n",
        "      x = nn.Dense(feat, name=f'layers_{i}')(x)\n",
        "      if i != len(self.features) - 1:\n",
        "        x = nn.relu(x)\n",
        "      # providing a name is optional though!\n",
        "      # the default autonames would be \"Dense_0\", \"Dense_1\", ...\n",
        "    return x\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
        "x = random.uniform(key1, (4,4))\n",
        "\n",
        "model = SimpleMLP(features=[3,4,5])\n",
        "params = model.init(key2, x)\n",
        "y = model.apply(params, x)\n",
        "\n",
        "print('initialized parameter shapes:\\n', jax.tree_util.tree_map(jnp.shape, unfreeze(params)))\n",
        "print('output:\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sav1CR1BQdUu",
        "outputId": "16fc9ef5-6b64-4727-8cd7-8a40e642763b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialized parameter shapes:\n",
            " {'params': {'layers_0': {'bias': (3,), 'kernel': (4, 3)}, 'layers_1': {'bias': (4,), 'kernel': (3, 4)}, 'layers_2': {'bias': (5,), 'kernel': (4, 5)}}}\n",
            "output:\n",
            " [[ 0.          0.          0.          0.          0.        ]\n",
            " [ 0.0072379  -0.00810348 -0.0255094   0.02151717 -0.01261241]\n",
            " [ 0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델이 간단하므로 `@nn.compact` 어노테이션을 사용하여 setup 대체\n",
        "\n",
        "두 가지 방법의 차이\n",
        "- `setup`에서는 sublayer를 네이밍할 수 있고, 향후 사용을 위해 킵해둘 수 있음\n",
        "- 여러 메서드를 사용하려면 `setup`을 사용. `@nn.compact` 어노테이션은 하나의 메서드에만 허용됨"
      ],
      "metadata": {
        "id": "qNw2yJ9pRrqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDense(nn.Module):\n",
        "  features: int\n",
        "  kernel_init: Callable = nn.initializers.lecun_normal()\n",
        "  bias_init: Callable = nn.initializers.zeros_init()\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    kernel = self.param('kernel',\n",
        "                        self.kernel_init, # Initialization function\n",
        "                        (inputs.shape[-1], self.features))  # shape info.\n",
        "    y = lax.dot_general(inputs, kernel,\n",
        "                        (((inputs.ndim - 1,), (0,)), ((), ())),) # TODO Why not jnp.dot?\n",
        "    bias = self.param('bias', self.bias_init, (self.features,))\n",
        "    y = y + bias\n",
        "    return y\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
        "x = random.uniform(key1, (4,4))\n",
        "\n",
        "model = SimpleDense(features=3)\n",
        "params = model.init(key2, x)\n",
        "y = model.apply(params, x)\n",
        "\n",
        "print('initialized parameters:\\n', params)\n",
        "print('output:\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI7ceGXeRYET",
        "outputId": "a0ddf394-5d16-4b47-f1c7-9e39b50cea4f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialized parameters:\n",
            " FrozenDict({\n",
            "    params: {\n",
            "        kernel: Array([[ 0.61506   , -0.22728713,  0.6054702 ],\n",
            "               [-0.29617992,  1.1232013 , -0.879759  ],\n",
            "               [-0.35162622,  0.3806491 ,  0.6893246 ],\n",
            "               [-0.1151355 ,  0.04567898, -1.091212  ]], dtype=float32),\n",
            "        bias: Array([0., 0., 0.], dtype=float32),\n",
            "    },\n",
            "})\n",
            "output:\n",
            " [[-0.02996203  1.102088   -0.6660265 ]\n",
            " [-0.31092793  0.63239413 -0.53678817]\n",
            " [ 0.01424009  0.9424717  -0.63561463]\n",
            " [ 0.3681896   0.3586519  -0.00459218]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dense layer 없으면 이렇게 직접 사용. `param` 함수 사용"
      ],
      "metadata": {
        "id": "vJXt3Sw2T5fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiasAdderWithRunningMean(nn.Module):\n",
        "  decay: float = 0.99\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    # easy pattern to detect if we're initializing via empty variable tree\n",
        "    is_initialized = self.has_variable('batch_stats', 'mean')\n",
        "    ra_mean = self.variable('batch_stats', 'mean',\n",
        "                            lambda s: jnp.zeros(s),\n",
        "                            x.shape[1:])\n",
        "    mean = ra_mean.value # This will either get the value or trigger init\n",
        "    bias = self.param('bias', lambda rng, shape: jnp.zeros(shape), x.shape[1:])\n",
        "    if is_initialized:\n",
        "      ra_mean.value = self.decay * ra_mean.value + (1.0 - self.decay) * jnp.mean(x, axis=0, keepdims=True)\n",
        "\n",
        "    return x - ra_mean.value + bias\n",
        "\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
        "x = jnp.ones((10,5))\n",
        "model = BiasAdderWithRunningMean()\n",
        "variables = model.init(key1, x)\n",
        "print('initialized variables:\\n', variables)\n",
        "y, updated_state = model.apply(variables, x, mutable=['batch_stats'])\n",
        "print('updated state:\\n', updated_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm2CkS9uSpeg",
        "outputId": "baf7781c-8fff-4e55-8e5f-931c61464c23"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialized variables:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([0., 0., 0., 0., 0.], dtype=float32),\n",
            "    },\n",
            "    params: {\n",
            "        bias: Array([0., 0., 0., 0., 0.], dtype=float32),\n",
            "    },\n",
            "})\n",
            "updated state:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.01, 0.01, 0.01, 0.01, 0.01]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`variable` 변수를 사용하여 파라미터를 넘어서는 변수 선언"
      ],
      "metadata": {
        "id": "sjo5DTr1Ue78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for val in [1.0, 2.0, 3.0]:\n",
        "  x = val * jnp.ones((10,5))\n",
        "  y, updated_state = model.apply(variables, x, mutable=['batch_stats'])\n",
        "  old_state, params = variables.pop('params')\n",
        "  variables = freeze({'params': params, **updated_state})\n",
        "  print('updated state:\\n', updated_state) # Shows only the mutable part"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7XMYgFHUGHw",
        "outputId": "20184a54-7deb-471d-b870-cdf85c86acc4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updated state:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.01, 0.01, 0.01, 0.01, 0.01]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "updated state:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.0299, 0.0299, 0.0299, 0.0299, 0.0299]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "updated state:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.059601, 0.059601, 0.059601, 0.059601, 0.059601]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "@partial(jax.jit, static_argnums=(0, 1))\n",
        "def update_step(tx, apply_fn, x, opt_state, params, state):\n",
        "\n",
        "  def loss(params):\n",
        "    y, updated_state = apply_fn({'params': params, **state},\n",
        "                                x, mutable=list(state.keys()))\n",
        "    l = ((x - y) ** 2).sum()\n",
        "    return l, updated_state\n",
        "\n",
        "  (l, state), grads = jax.value_and_grad(loss, has_aux=True)(params)\n",
        "  updates, opt_state = tx.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return opt_state, params, state\n",
        "\n",
        "x = jnp.ones((10,5))\n",
        "variables = model.init(random.PRNGKey(0), x)\n",
        "state, params = variables.pop('params')\n",
        "del variables\n",
        "tx = optax.sgd(learning_rate=0.02)\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for _ in range(3):\n",
        "  opt_state, params, state = update_step(tx, model.apply, x, opt_state, params, state)\n",
        "  print('Updated state: ', state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urbXvSsiXBHS",
        "outputId": "0d17047c-8fe0-44b3-e20b-52a47494fe4f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated state:  FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.01, 0.01, 0.01, 0.01, 0.01]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "Updated state:  FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.0199, 0.0199, 0.0199, 0.0199, 0.0199]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "Updated state:  FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.029701, 0.029701, 0.029701, 0.029701, 0.029701]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ]
        }
      ]
    }
  ]
}