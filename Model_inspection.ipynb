{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN74apWAxO8O+0oxIEE08Qe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talkin24/jaxflax_lab/blob/main/Model_inspection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model surgery\n",
        "\n",
        "일반적으로 Flax 모듈과 옵티마이저는 파라미터를 추적하고 업데이트합니다. 하지만 모델 작업을 수행하고 파라미터 텐서를 직접 조정하고 싶을 때가 있을 수 있습니다. 이 가이드는 그 방법을 보여줍니다."
      ],
      "metadata": {
        "id": "1MFy_mMteude"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "5vNxJGd2r2Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q pip jax jaxlib flax\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8KaXKowr5xM",
        "outputId": "414356c3-dce7-4443-ba9b-b525c8de29c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/2.1 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import traverse_util\n",
        "from flax import linen as nn\n",
        "from flax.core import freeze\n",
        "import jax\n",
        "import optax"
      ],
      "metadata": {
        "id": "IE-iWhgWr7Qy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Surgery with Flax Modules\n",
        "\n",
        "데모를 위해 작은 컨볼루션 신경망 모델을 만들어 보겠습니다.\n",
        "\n",
        "평소처럼 `CNN.init(...)['params']`를 실행하여 훈련의 모든 단계에서 `params`를 전달하고 수정할 수 있습니다."
      ],
      "metadata": {
        "id": "mp-ZKimyr9IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "      x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "      x = nn.relu(x)\n",
        "      x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "      x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "      x = nn.relu(x)\n",
        "      x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "      x = x.reshape((x.shape[0], -1))\n",
        "      x = nn.Dense(features=256)(x)\n",
        "      x = nn.relu(x)\n",
        "      x = nn.Dense(features=10)(x)\n",
        "      x = nn.log_softmax(x)\n",
        "      return x\n",
        "\n",
        "def get_initial_params(key):\n",
        "    init_shape = jnp.ones((1, 28, 28, 1), jnp.float32)\n",
        "    initial_params = CNN().init(key, init_shape)['params']\n",
        "    return initial_params\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "params = get_initial_params(key)\n",
        "\n",
        "jax.tree_util.tree_map(jnp.shape, params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAhaf9sfsJ65",
        "outputId": "96c7632f-471e-4f44-8252-ca3bd6f77449"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    Conv_0: {\n",
              "        bias: (32,),\n",
              "        kernel: (3, 3, 1, 32),\n",
              "    },\n",
              "    Conv_1: {\n",
              "        bias: (64,),\n",
              "        kernel: (3, 3, 32, 64),\n",
              "    },\n",
              "    Dense_0: {\n",
              "        bias: (256,),\n",
              "        kernel: (3136, 256),\n",
              "    },\n",
              "    Dense_1: {\n",
              "        bias: (10,),\n",
              "        kernel: (256, 10),\n",
              "    },\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`params`로 반환되는 것은 커널과 바이어스로 몇 개의 JAX 배열을 포함하는 `FrozenDict`입니다.\n",
        "\n",
        "`FrozenDict`는 읽기 전용 딕셔너리에 불과하며, Flax는 JAX 배열이 불변이고 새 `params`가 이전 `params`를 대체해야 하는 JAX의 기능적 특성 때문에 이를 읽기 전용으로 만들었습니다. 딕셔너리를 읽기 전용으로 만들면 학습 및 업데이트 중에 실수로 딕셔너리가 제자리에서 변경되지 않도록 할 수 있습니다.\n",
        "\n",
        "Flax 모듈 외부에서 실제로 매개변수를 수정하는 한 가지 방법은 명시적으로 플랫화하여 변경 가능한 딕셔너리를 만드는 것입니다. 중첩된 모든 키를 결합하려면 구분 기호 `sep`을 사용할 수 있습니다. `sep`을 지정하지 않으면 키는 중첩된 모든 키의 튜플이 됩니다."
      ],
      "metadata": {
        "id": "G99ajLTjsfFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a flattened key-value list.\n",
        "flat_params = traverse_util.flatten_dict(params, sep='/')\n",
        "\n",
        "jax.tree_util.tree_map(jnp.shape, flat_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC1aWeJUs3So",
        "outputId": "3fd217d0-5a2e-40b1-9c1a-6e86e864bdc9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Conv_0/bias': (32,),\n",
              " 'Conv_0/kernel': (3, 3, 1, 32),\n",
              " 'Conv_1/bias': (64,),\n",
              " 'Conv_1/kernel': (3, 3, 32, 64),\n",
              " 'Dense_0/bias': (256,),\n",
              " 'Dense_0/kernel': (3136, 256),\n",
              " 'Dense_1/bias': (10,),\n",
              " 'Dense_1/kernel': (256, 10)}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 파라미터를 원하는 대로 설정할 수 있습니다. 작업이 끝나면 다시 평평하게 만들어 향후 훈련에 사용하세요."
      ],
      "metadata": {
        "id": "-6f_aY9otKbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Somehow modify a layer\n",
        "dense_kernel = flat_params['Dense_1/kernel']\n",
        "flat_params['Dense_1/kernel'] = dense_kernel / jnp.linalg.norm(dense_kernel)\n",
        "\n",
        "# Unflatten.\n",
        "unflat_params = traverse_util.unflatten_dict(flat_params, sep='/')\n",
        "# Refreeze.\n",
        "unflat_params = freeze(unflat_params)\n",
        "jax.tree_util.tree_map(jnp.shape, unflat_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6fZqrdCtOxd",
        "outputId": "dfd989a0-e0e0-4d29-9cf0-82cc9a2e4b74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    Conv_0: {\n",
              "        bias: (32,),\n",
              "        kernel: (3, 3, 1, 32),\n",
              "    },\n",
              "    Conv_1: {\n",
              "        bias: (64,),\n",
              "        kernel: (3, 3, 32, 64),\n",
              "    },\n",
              "    Dense_0: {\n",
              "        bias: (256,),\n",
              "        kernel: (3136, 256),\n",
              "    },\n",
              "    Dense_1: {\n",
              "        bias: (10,),\n",
              "        kernel: (256, 10),\n",
              "    },\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Surgery with Optimizers\n",
        "\n",
        "`Optax`를 옵티마이저로 사용할 때 `opt_state`는 실제로 옵티마이저를 구성하는 개별 그라데이션 변환의 상태가 중첩된 튜플입니다. \n",
        "\n",
        "이러한 상태에는 매개변수 트리를 미러링하는 pytree가 포함되어 있으며, 평탄화, 수정, 평탄화 해제, 원래 상태를 미러링하는 새로운 옵티마이저 상태 재생성 등 동일한 방식으로 수정할 수 있습니다."
      ],
      "metadata": {
        "id": "wr15BB9OtXuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tx = optax.adam(1.0)\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "# The optimizer state is a tuple of gradient transformation states.\n",
        "jax.tree_util.tree_map(jnp.shape, opt_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruqRHI87ttbz",
        "outputId": "2c5fb22c-3f6f-42bb-a2bc-f69ac93a4177"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(ScaleByAdamState(count=(), mu=FrozenDict({\n",
              "     Conv_0: {\n",
              "         bias: (32,),\n",
              "         kernel: (3, 3, 1, 32),\n",
              "     },\n",
              "     Conv_1: {\n",
              "         bias: (64,),\n",
              "         kernel: (3, 3, 32, 64),\n",
              "     },\n",
              "     Dense_0: {\n",
              "         bias: (256,),\n",
              "         kernel: (3136, 256),\n",
              "     },\n",
              "     Dense_1: {\n",
              "         bias: (10,),\n",
              "         kernel: (256, 10),\n",
              "     },\n",
              " }), nu=FrozenDict({\n",
              "     Conv_0: {\n",
              "         bias: (32,),\n",
              "         kernel: (3, 3, 1, 32),\n",
              "     },\n",
              "     Conv_1: {\n",
              "         bias: (64,),\n",
              "         kernel: (3, 3, 32, 64),\n",
              "     },\n",
              "     Dense_0: {\n",
              "         bias: (256,),\n",
              "         kernel: (3136, 256),\n",
              "     },\n",
              "     Dense_1: {\n",
              "         bias: (10,),\n",
              "         kernel: (256, 10),\n",
              "     },\n",
              " })),\n",
              " EmptyState())"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "옵티마이저 상태 내부의 파이트리는 파라미터와 동일한 구조를 따르며 정확히 동일한 방식으로 평평하게 하거나 수정할 수 있습니다."
      ],
      "metadata": {
        "id": "hSCF-8V2t3G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flat_mu = traverse_util.flatten_dict(opt_state[0].mu, sep='/')\n",
        "flat_nu = traverse_util.flatten_dict(opt_state[0].nu, sep='/')\n",
        "\n",
        "jax.tree_util.tree_map(jnp.shape, flat_mu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c9J39Zct6-w",
        "outputId": "a55b80d9-324e-4650-edb1-0b1a6d80d26d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Conv_0/bias': (32,),\n",
              " 'Conv_0/kernel': (3, 3, 1, 32),\n",
              " 'Conv_1/bias': (64,),\n",
              " 'Conv_1/kernel': (3, 3, 32, 64),\n",
              " 'Dense_0/bias': (256,),\n",
              " 'Dense_0/kernel': (3136, 256),\n",
              " 'Dense_1/bias': (10,),\n",
              " 'Dense_1/kernel': (256, 10)}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "수정 후 최적화 상태를 다시 생성합니다. 향후 훈련에 활용하세요."
      ],
      "metadata": {
        "id": "ac7622oWuE7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt_state = (\n",
        "    opt_state[0]._replace(\n",
        "        mu=traverse_util.unflatten_dict(flat_mu, sep='/'),\n",
        "        nu=traverse_util.unflatten_dict(flat_nu, sep='/'),\n",
        "    ),\n",
        ") + opt_state[1:]\n",
        "jax.tree_util.tree_map(jnp.shape, opt_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oauSDIBAuJ3O",
        "outputId": "a3e7114f-f1af-480c-dad2-fa277158bfc2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(ScaleByAdamState(count=(), mu={'Conv_0': {'bias': (32,), 'kernel': (3, 3, 1, 32)}, 'Conv_1': {'bias': (64,), 'kernel': (3, 3, 32, 64)}, 'Dense_0': {'bias': (256,), 'kernel': (3136, 256)}, 'Dense_1': {'bias': (10,), 'kernel': (256, 10)}}, nu={'Conv_0': {'bias': (32,), 'kernel': (3, 3, 1, 32)}, 'Conv_1': {'bias': (64,), 'kernel': (3, 3, 32, 64)}, 'Dense_0': {'bias': (256,), 'kernel': (3136, 256)}, 'Dense_1': {'bias': (10,), 'kernel': (256, 10)}}),\n",
              " EmptyState())"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting intermediate values\n",
        "\n",
        "이 패턴은 모듈에서 중간 값을 추출하는 방법을 보여줍니다. `nn.compact`를 사용하는 간단한 CNN부터 시작해 보겠습니다."
      ],
      "metadata": {
        "id": "zKbxfwz4ezrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from typing import Sequence\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    x = nn.Dense(features=256)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(features=10)(x)\n",
        "    x = nn.log_softmax(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "RNWnsFpqe3Gy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 모듈은 `nn.compact`를 사용하기 때문에 중간 값에 직접 액세스할 수 없습니다. 중간값을 노출하는 몇 가지 방법이 있습니다."
      ],
      "metadata": {
        "id": "OZ_j5TD3upg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store intermediate values in a new variable collection\n",
        "\n",
        "CNN은 다음과 같이 중간체를 저장하기 위한 `sow` 호출로 보강할 수 있습니다:"
      ],
      "metadata": {
        "id": "XwKlGRogumAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default CNN\n",
        "class CNN(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "\n",
        "    x = nn.Dense(features=256)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(features=10)(x)\n",
        "    x = nn.log_softmax(x)\n",
        "    return x\n",
        "\n",
        "# CNN using sow API\n",
        "class SowCNN(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    self.sow('intermediates', 'features', x) #####\n",
        "    x = nn.Dense(features=256)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(features=10)(x)\n",
        "    x = nn.log_softmax(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "_LBXCEtGu24Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`sow`는 변수 컬렉션이 변경 가능하지 않을 때 no-op으로 작동합니다. 따라서 디버깅 및 중간체의 선택적 추적에 완벽하게 작동합니다. 'intermediates' 컬렉션은 `capture_intermediates` API에서도 사용됩니다(마지막 섹션 참조).\n",
        "\n",
        "기본적으로 `sow`는 호출될 때마다 값을 추가한다는 점에 유의하세요:\n",
        "\n",
        "- 이는 모듈이 인스턴스화되면 부모 모듈에서 여러 번 호출될 수 있고, 모든 파종된 값을 포착하고 싶기 때문에 필요합니다.\n",
        "\n",
        "- 따라서 `변수`에 중간 값을 다시 넣지 않도록 해야 합니다. 그렇지 않으면 호출할 때마다 해당 튜플의 길이가 증가하고 재컴파일이 트리거됩니다.\n",
        "\n",
        "- 기본 추가 동작을 재정의하려면 `Module.sow()`를 참조하여 `init_fn` 및 `reduce_fn`을 지정하세요."
      ],
      "metadata": {
        "id": "F1pJ1BmnvErz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SowCNN2(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    mod = SowCNN(name='SowCNN')\n",
        "    return mod(x) + mod(x)  # Calling same module instance twice.\n",
        "\n",
        "@jax.jit\n",
        "def init(key, x):\n",
        "  variables = SowCNN2().init(key, x)\n",
        "  # By default the 'intermediates' collection is not mutable during init.\n",
        "  # So variables will only contain 'params' here.\n",
        "  return variables\n",
        "\n",
        "@jax.jit\n",
        "def predict(variables, x):\n",
        "  # If mutable='intermediates' is not specified, then .sow() acts as a noop.\n",
        "  output, mod_vars = SowCNN2().apply(variables, x, mutable='intermediates')\n",
        "  features = mod_vars['intermediates']['SowCNN']['features']\n",
        "  return output, features\n",
        "\n",
        "batch = jnp.ones((1,28,28,1))\n",
        "variables = init(jax.random.PRNGKey(0), batch)\n",
        "preds, feats = predict(variables, batch)\n",
        "\n",
        "assert len(feats) == 2  # Tuple with two values since module was called twice."
      ],
      "metadata": {
        "id": "5xvIjR7Yu_k6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVpkUzSHva19",
        "outputId": "081c50c1-7f43-417f-acce-cafc6de34266"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Array([[0.1793044 , 0.        , 0.3081015 , ..., 0.2719369 , 0.03271667,\n",
              "         0.40916097]], dtype=float32),\n",
              " Array([[0.1793044 , 0.        , 0.3081015 , ..., 0.2719369 , 0.03271667,\n",
              "         0.40916097]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refactor module into submodules\n",
        "\n",
        "이 패턴은 서브모듈을 분할할 특정 방식이 분명한 경우에 유용합니다. `setup`에서 노출하는 모든 서브모듈을 직접 사용할 수 있습니다. 제한적으로 `setup`에서 모든 서브모듈을 정의하고 `nn.compact`를 전혀 사용하지 않을 수 있습니다."
      ],
      "metadata": {
        "id": "AaDrU9ZBvw8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RefactoredCNN(nn.Module):\n",
        "  def setup(self):\n",
        "    self.features = Features()\n",
        "    self.classifier = Classifier()\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "class Features(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    return x\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Dense(features=256)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(features=10)(x)\n",
        "    x = nn.log_softmax(x)\n",
        "    return x\n",
        "\n",
        "@jax.jit\n",
        "def init(key, x):\n",
        "  variables = RefactoredCNN().init(key, x)\n",
        "  return variables['params']\n",
        "\n",
        "@jax.jit\n",
        "def features(params, x):\n",
        "  return RefactoredCNN().apply({\"params\": params}, x,\n",
        "    method=lambda module, x: module.features(x))\n",
        "\n",
        "params = init(jax.random.PRNGKey(0), batch)\n",
        "\n",
        "features(params, batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjyOvX6yvptA",
        "outputId": "49bfb2e3-c7bb-459d-9f28-57314aa9f36f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[0.        , 0.01445577, 0.73324203, ..., 0.        , 0.        ,\n",
              "        0.21551636]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use `capture_intermediates`\n",
        "\n",
        "Linen은 코드 변경 없이 서브모듈에서 중간 반환값을 자동으로 캡처할 수 있도록 지원합니다. 이 패턴은 중간값을 캡처하는 \"sledge hammer\" 접근 방식으로 간주해야 합니다. 디버깅 및 검사 도구로서 매우 유용하지만 이 하우투에 설명된 다른 패턴을 사용하는 것도 좋습니다.\n",
        "\n",
        "다음 코드 예제에서는 중간 활성화가 비한정(NaN 또는 무한)인지 여부를 확인합니다:"
      ],
      "metadata": {
        "id": "HxLyKa1av-g-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def init(key, x):\n",
        "  variables = CNN().init(key, x)\n",
        "  return variables\n",
        "\n",
        "@jax.jit\n",
        "def predict(variables, x):\n",
        "  y, state = CNN().apply(variables, x, capture_intermediates=True, mutable=[\"intermediates\"])\n",
        "  intermediates = state['intermediates']\n",
        "  fin = jax.tree_util.tree_map(lambda xs: jnp.all(jnp.isfinite(xs)), intermediates)\n",
        "  return y, fin\n",
        "\n",
        "variables = init(jax.random.PRNGKey(0), batch)\n",
        "y, is_finite = predict(variables, batch)\n",
        "all_finite = all(jax.tree_util.tree_leaves(is_finite))\n",
        "assert all_finite, \"non-finite intermediate detected!\""
      ],
      "metadata": {
        "id": "_FOZdGN4xcBd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_finite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy4lYETkxeJJ",
        "outputId": "81facf4e-4eb8-4477-f53e-cad83f53824b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    Conv_0: {\n",
              "        __call__: (Array(True, dtype=bool),),\n",
              "    },\n",
              "    Conv_1: {\n",
              "        __call__: (Array(True, dtype=bool),),\n",
              "    },\n",
              "    Dense_0: {\n",
              "        __call__: (Array(True, dtype=bool),),\n",
              "    },\n",
              "    Dense_1: {\n",
              "        __call__: (Array(True, dtype=bool),),\n",
              "    },\n",
              "    __call__: (Array(True, dtype=bool),),\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적으로 `__call__` 메서드의 중간체만 수집됩니다. \n",
        "\n",
        "또는 `Module` 인스턴스와 메서드 이름을 기반으로 사용자 정의 필터를 전달할 수 있습니다."
      ],
      "metadata": {
        "id": "-rda37pb0FPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_Dense = lambda mdl, method_name: isinstance(mdl, nn.Dense)\n",
        "filter_encodings = lambda mdl, method_name: method_name == \"encode\"\n",
        "\n",
        "y, state = CNN().apply(variables, batch, capture_intermediates=filter_Dense, mutable=[\"intermediates\"])\n",
        "dense_intermediates = state['intermediates']"
      ],
      "metadata": {
        "id": "UTOWr7wwzfK_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_intermediates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnvgafGC0FB3",
        "outputId": "aab7ea7d-202b-4f17-fbec-2ad163efc58f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    Dense_0: {\n",
              "        __call__: (Array([[-0.4163544 , -0.06839216, -0.51570624, -0.19137715,  0.10282888,\n",
              "                 0.5738754 ,  0.13795005,  0.18073687,  0.00480315,  0.64715713,\n",
              "                 0.3356169 , -0.4829922 ,  0.4347183 ,  0.51078403, -0.449439  ,\n",
              "                 0.17263898,  0.22860987,  0.08530779,  0.25815383,  0.06415588,\n",
              "                -0.1518939 , -0.23635048,  0.27043548, -0.1065058 ,  0.24950364,\n",
              "                 0.2170637 ,  0.11157337, -0.08237511, -0.19511226,  0.2964567 ,\n",
              "                 0.02076684, -0.3986773 , -0.5505137 ,  0.6888312 , -0.3276731 ,\n",
              "                 0.16291578,  0.36783996, -0.46132872, -0.32510972, -0.04895904,\n",
              "                -0.36039907,  0.26155755, -0.32220736, -0.04482261, -0.20064123,\n",
              "                -0.08618929,  0.55833423, -0.38625807,  0.15436846,  0.38278913,\n",
              "                -0.2882816 ,  0.0843855 ,  0.4771748 , -0.14847872,  0.6558553 ,\n",
              "                 0.03806313, -0.41578537,  0.01439955, -0.21037483, -0.12324268,\n",
              "                 0.33417988, -0.11690824, -0.35994297,  0.5808315 , -0.00361295,\n",
              "                 0.02130705,  0.44581988, -0.29119238,  0.34520045, -0.22596323,\n",
              "                -0.58577794, -0.02006999, -0.05664963,  0.23593934,  0.20214057,\n",
              "                -0.33238682,  0.00458746, -0.04685856, -0.4828149 ,  0.33724213,\n",
              "                -0.10357607, -1.0607941 , -0.30165178,  0.51962996,  0.0534321 ,\n",
              "                -0.08746013, -0.4704664 , -0.14081477,  0.48973024,  0.05132436,\n",
              "                -0.39865947,  0.54428905,  0.47708592,  0.1485857 ,  0.05624074,\n",
              "                 0.13775477, -0.23520088,  0.15714636, -0.03239169,  0.3406411 ,\n",
              "                -0.10655045, -0.5191837 , -0.29110307, -0.0068013 , -0.13546336,\n",
              "                -0.5979314 , -0.06798462, -0.23552822, -0.11212861,  0.537155  ,\n",
              "                -0.3496435 ,  0.04408696, -0.22866215, -0.04749561, -0.03210368,\n",
              "                -0.08093808,  0.08917187,  0.36939037, -0.21056946,  0.0708899 ,\n",
              "                 0.38987833,  0.08386803,  0.4953683 ,  0.44249094,  0.46253425,\n",
              "                 0.34993693, -0.05809946, -0.23589213, -0.00878994, -0.258719  ,\n",
              "                 0.2768897 , -0.46381542,  0.31134278,  0.47266963, -0.22087142,\n",
              "                -0.17776516, -0.09034463,  0.03917294, -0.34750885, -0.5797967 ,\n",
              "                 0.41952965, -0.47485486, -0.34812948,  0.03231033,  0.05712842,\n",
              "                 0.06600054,  0.38005087, -0.32156777,  0.04818754,  0.07405008,\n",
              "                 0.04843425,  0.31814113,  0.07259842, -0.0576856 , -0.12510772,\n",
              "                -0.06850094,  0.3044375 ,  0.17437436, -0.21650574, -0.11063135,\n",
              "                -0.5771674 , -0.38540745,  0.59977067, -0.56478536,  0.27418256,\n",
              "                 0.35842   ,  0.01140791,  0.03134273,  0.32842252,  0.2111106 ,\n",
              "                 0.28517342,  0.21730214, -0.11192834, -0.04882291,  0.02462055,\n",
              "                -0.20947076,  0.41051534, -0.30978185, -0.14983289, -0.3956893 ,\n",
              "                -0.28847355, -0.6793068 ,  0.37252006,  0.01141983,  0.33859324,\n",
              "                -0.27796546, -0.35619354, -0.3501715 ,  0.21344084,  0.7108663 ,\n",
              "                 0.15249707,  0.09329379, -0.04598783,  0.54599065,  0.10921239,\n",
              "                -0.18835582, -0.0782226 , -0.34011185,  0.27967605,  0.33026803,\n",
              "                -0.26274192,  0.23383096, -0.08285567, -0.01237454, -0.05343712,\n",
              "                -0.0728799 , -0.81387216, -0.13973129, -0.45498863,  0.12424163,\n",
              "                 0.46915185,  0.3577314 ,  0.6243864 , -0.4276121 , -0.3719736 ,\n",
              "                -0.5789334 ,  0.06463195, -0.25565723, -0.04231032,  0.21422103,\n",
              "                 0.05562961, -0.08459084, -0.11845741, -0.34413996, -0.3046914 ,\n",
              "                 0.08290206,  0.08328494,  0.17103559, -0.15051481, -0.06130677,\n",
              "                 0.0102952 , -0.11659203,  0.0695093 , -0.35063067, -0.36402225,\n",
              "                 0.5017304 , -0.46088937, -0.22126119,  0.04045497,  0.07049579,\n",
              "                -0.1392924 ,  0.11205108, -0.09623215,  0.28672752,  0.2742621 ,\n",
              "                 0.13183247,  0.23342657,  0.03459335, -0.05502995,  0.15352842,\n",
              "                 0.2987794 ,  0.2849027 , -0.09937888,  0.30473265, -0.06539315,\n",
              "                -0.71288306]], dtype=float32),),\n",
              "    },\n",
              "    Dense_1: {\n",
              "        __call__: (Array([[-0.08110129, -0.19879039,  0.21372153,  0.05252018, -0.11855111,\n",
              "                -0.017984  , -0.14921135, -0.3125882 , -0.3944908 ,  0.06802002]],      dtype=float32),),\n",
              "    },\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use `Sequential`\n",
        "\n",
        "`Sequential` 결합기의 간단한 구현을 사용하여 CNN을 정의할 수도 있습니다(이는 보다 상태 저장 접근 방식에서 매우 일반적입니다). \n",
        "\n",
        "이는 매우 간단한 모델에 유용할 수 있으며 임의의 모델 조작이 가능합니다. 하지만 매우 제한적일 수 있습니다. 조건부 하나라도 추가하려면 `Sequential`에서 벗어나 리팩터링하고 모델을 더 명시적으로 구조화해야 합니다."
      ],
      "metadata": {
        "id": "9Sh9mi5R0PUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sequential(nn.Module):\n",
        "  layers: Sequence[nn.Module]\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "def SeqCNN():\n",
        "  return Sequential([\n",
        "    nn.Conv(features=32, kernel_size=(3, 3)),\n",
        "    nn.relu,\n",
        "    lambda x: nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2)),\n",
        "    nn.Conv(features=64, kernel_size=(3, 3)),\n",
        "    nn.relu,\n",
        "    lambda x: nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2)),\n",
        "    lambda x: x.reshape((x.shape[0], -1)),  # flatten\n",
        "    nn.Dense(features=256),\n",
        "    nn.relu,\n",
        "    nn.Dense(features=10),\n",
        "    nn.log_softmax,\n",
        "  ])\n",
        "\n",
        "@jax.jit\n",
        "def init(key, x):\n",
        "  variables = SeqCNN().init(key, x)\n",
        "  return variables['params']\n",
        "\n",
        "@jax.jit\n",
        "def features(params, x):\n",
        "  return Sequential(SeqCNN().layers[0:7]).apply({\"params\": params}, x)\n",
        "\n",
        "params = init(jax.random.PRNGKey(0), batch)\n",
        "features(params, batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N593nskR01q1",
        "outputId": "ecd9d880-b6b4-4ec3-ad32-8821dcbfb860"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[0.7018405 , 0.        , 1.0706136 , ..., 0.12816615, 0.00970969,\n",
              "        0.04631865]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting gradients of intermdeiate values\n",
        "\n",
        "디버깅 목적으로 중간 값의 그라데이션을 추출하는 것이 유용할 수 있습니다. 원하는 값에 대해 `Module.perturb()` 메서드를 사용하면 이 작업을 수행할 수 있습니다."
      ],
      "metadata": {
        "id": "CcFnwfNV033Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.relu(nn.Dense(8)(x))\n",
        "    x = self.perturb('hidden', x)\n",
        "    x = nn.Dense(2)(x)\n",
        "    x = self.perturb('logits', x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "t1tOr25H1GQQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`perturb`는 기본적으로 `perturbations` 컬렉션에 변수를 추가하며, identity 함수처럼 동작하고 perturbation의 기울기가 입력의 기울기와 일치합니다. perturbations을 얻으려면 모델을 초기화하기만 하면 됩니다:"
      ],
      "metadata": {
        "id": "sKSJCQRh1OIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = jnp.empty((1, 4)) # random data\n",
        "y = jnp.empty((1, 2)) # random data\n",
        "\n",
        "model = Model()\n",
        "variables = model.init(jax.random.PRNGKey(1), x)\n",
        "params, perturbations = variables['params'], variables['perturbations']"
      ],
      "metadata": {
        "id": "jWs5mYC41J9o"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로 perturbation에 대한 손실의 기울기를 계산하면 중간체의 기울기와 일치하게 됩니다:"
      ],
      "metadata": {
        "id": "ouP_5GQt1gB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(params, perturbations, x, y):\n",
        "  y_pred = model.apply({'params': params, 'perturbations': perturbations}, x)\n",
        "  return jnp.mean((y_pred - y) ** 2)\n",
        "\n",
        "intermediate_grads = jax.grad(loss_fn, argnums=1)(params, perturbations, x, y)"
      ],
      "metadata": {
        "id": "w3qYwhNh1msr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intermediate_grads"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuseJLwe1oE_",
        "outputId": "c06222d3-6fd5-47cd-d99d-ec454e2e7f03"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    hidden: Array([[0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32),\n",
              "    logits: Array([[0., 0.]], dtype=float32),\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GSLy1_2W1p_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}