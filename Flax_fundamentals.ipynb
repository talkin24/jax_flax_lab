{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmq/HkQFR+cVaTz2q4isd+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talkin24/jaxflax_lab/blob/main/Flax_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_876emofoNDq",
        "outputId": "f9195dcf-03c3-4b4c-b507-442ff31d6f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install the latest JAXlib version.\n",
        "!pip install --upgrade -q pip jax jaxlib\n",
        "# Install Flax at head:\n",
        "!pip install --upgrade -q git+https://github.com/google/flax.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "from typing import Any, Callable, Sequence\n",
        "from jax import lax, random, numpy as jnp\n",
        "from flax.core import freeze, unfreeze\n",
        "from flax import linen as nn"
      ],
      "metadata": {
        "id": "h_q1NtOpqEEd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We create one dense layer instance (taking 'features' parameter as input)\n",
        "model = nn.Dense(features=5)"
      ],
      "metadata": {
        "id": "XNDwdmtnqGuz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "출력만 입력하면 됨"
      ],
      "metadata": {
        "id": "tAkxggqluHaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Parameters & initialization\n",
        "\n",
        "- 파라미터는 모델에 저장되지 않음. init 함수를 호출하여 초기화해주어야 함. 이때 PRNGKey와 더미 인풋을 사용함."
      ],
      "metadata": {
        "id": "b_A2RrtYqj1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key1, key2 = random.split(random.PRNGKey(0))\n",
        "x = random.normal(key1, (10,)) # Dummy input data\n",
        "params = model.init(key2, x) # Initialization call\n",
        "jax.tree_util.tree_map(lambda x: x.shape, params) # Checking output shapes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdv2i8ikqT8m",
        "outputId": "9934db07-6bfc-482c-cf06-be6c01909f87"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    params: {\n",
              "        bias: (5,),\n",
              "        kernel: (10, 5),\n",
              "    },\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- JAX/FLAX는 numpy처럼 row-based 시스템. 벡터는 행 벡터 기준임\n",
        "\n",
        "- `init_with_output` 메소드로 더미 인풋의 forward pass 출력도 함께 리턴 가능\n",
        "\n",
        "- 출력은 FrozenDict 인스턴스로 저장됨. 이는 immutable하며 사용자가 이를 인식하게 도와줌.\n",
        "\n"
      ],
      "metadata": {
        "id": "WZCmbEu3rNAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    params['new_key'] = jnp.ones((2,2))\n",
        "except ValueError as e:\n",
        "    print(\"Error: \", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZVBtEOFqhAJ",
        "outputId": "542f229f-8876-4617-e2d4-520b5ab22cb6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:  FrozenDict is immutable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.apply(params, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wAaVOvorK6t",
        "outputId": "876efbca-1e0d-44de-a20e-41e6c4701d3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([-1.3721193 ,  0.61131495,  0.6442836 ,  2.2192965 , -1.1271116 ],      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set problem dimensions.\n",
        "n_samples = 20\n",
        "x_dim = 10\n",
        "y_dim = 5\n",
        "\n",
        "# Generate random ground truth W and b.\n",
        "key = random.PRNGKey(0)\n",
        "k1, k2 = random.split(key)\n",
        "W = random.normal(k1, (x_dim, y_dim))\n",
        "b = random.normal(k2, (y_dim,))\n",
        "# Store the parameters in a FrozenDict pytree.\n",
        "true_params = freeze({'params': {'bias': b, 'kernel': W}})\n",
        "\n",
        "# Generate samples with additional noise.\n",
        "key_sample, key_noise = random.split(k1)\n",
        "x_samples = random.normal(key_sample, (n_samples, x_dim))\n",
        "y_samples = jnp.dot(x_samples, W) + b + 0.1 * random.normal(key_noise,(n_samples, y_dim))\n",
        "print('x shape:', x_samples.shape, '; y shape:', y_samples.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K09Q9fwxwTsX",
        "outputId": "54d078c1-fc5c-4490-af3a-6e1160c01558"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: (20, 10) ; y shape: (20, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as JAX version but using model.apply().\n",
        "@jax.jit\n",
        "def mse(params, x_batched, y_batched):\n",
        "  # Define the squared loss for a single pair (x,y)\n",
        "  def squared_error(x, y):\n",
        "    pred = model.apply(params, x)\n",
        "    return jnp.inner(y-pred, y-pred) / 2.0\n",
        "  # Vectorize the previous to compute the average of the loss on all samples.\n",
        "  return jnp.mean(jax.vmap(squared_error)(x_batched,y_batched), axis=0)"
      ],
      "metadata": {
        "id": "XNmChSQMxlju"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.3  # Gradient step size.\n",
        "print('Loss for \"true\" W,b: ', mse(true_params, x_samples, y_samples))\n",
        "loss_grad_fn = jax.value_and_grad(mse)\n",
        "\n",
        "@jax.jit\n",
        "def update_params(params, learning_rate, grads):\n",
        "  params = jax.tree_util.tree_map(\n",
        "      lambda p, g: p - learning_rate * g, params, grads)\n",
        "  return params\n",
        "\n",
        "for i in range(101):\n",
        "  # Perform one gradient update.\n",
        "  loss_val, grads = loss_grad_fn(params, x_samples, y_samples)\n",
        "  params = update_params(params, learning_rate, grads)\n",
        "  if i % 10 == 0:\n",
        "    print(f'Loss step {i}: ', loss_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCv-Ij1g1URM",
        "outputId": "cbe8f95b-f92b-4f5e-9a84-2f5e02094fce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for \"true\" W,b:  0.02363979\n",
            "Loss step 0:  35.343876\n",
            "Loss step 10:  0.5143469\n",
            "Loss step 20:  0.11384159\n",
            "Loss step 30:  0.039326735\n",
            "Loss step 40:  0.019916208\n",
            "Loss step 50:  0.014209135\n",
            "Loss step 60:  0.012425654\n",
            "Loss step 70:  0.01185039\n",
            "Loss step 80:  0.011661784\n",
            "Loss step 90:  0.011599409\n",
            "Loss step 100:  0.011578695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing with Optax\n",
        "\n",
        "- Optax는 스케쥴링(시간에 따라 옵티마이저 파라미터 변경), 마스킹(트리별 다른 파라미터 업데이트)도 지원함"
      ],
      "metadata": {
        "id": "6RorphHh4C9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "tx = optax.adam(learning_rate=learning_rate)\n",
        "opt_state = tx.init(params)\n",
        "loss_grad_fn = jax.value_and_grad(mse)"
      ],
      "metadata": {
        "id": "_Hm5zS_V5pZB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Optimizer state도 설정해주어야 함"
      ],
      "metadata": {
        "id": "Sc2divv2K-f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(101):\n",
        "  loss_val, grads = loss_grad_fn(params, x_samples, y_samples)\n",
        "  updates, opt_state = tx.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  if i % 10 == 0:\n",
        "    print('Loss step {}: '.format(i), loss_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WynIzR36CbY",
        "outputId": "61845032-3639-4fc5-85e6-63ccd990090b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss step 0:  0.011577628\n",
            "Loss step 10:  0.26143155\n",
            "Loss step 20:  0.07675027\n",
            "Loss step 30:  0.03644055\n",
            "Loss step 40:  0.022012806\n",
            "Loss step 50:  0.016178599\n",
            "Loss step 60:  0.0130028\n",
            "Loss step 70:  0.012026141\n",
            "Loss step 80:  0.011764516\n",
            "Loss step 90:  0.0116460435\n",
            "Loss step 100:  0.011585529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`optax.apply_updates`로 업데이트 "
      ],
      "metadata": {
        "id": "7CB5HyeqLX-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serializing the result"
      ],
      "metadata": {
        "id": "g4ti7QiILjiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import serialization\n",
        "bytes_output = serialization.to_bytes(params)\n",
        "dict_output = serialization.to_state_dict(params)\n",
        "print('Dict output')\n",
        "print(dict_output)\n",
        "print('Bytes output')\n",
        "print(bytes_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2R1EXimLu4e",
        "outputId": "1c212f96-d641-4cfe-9895-f28397bb926c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dict output\n",
            "{'params': {'bias': Array([-1.4555768 , -2.0277991 ,  2.0790975 ,  1.2186145 , -0.99809754],      dtype=float32), 'kernel': Array([[ 1.0098814 ,  0.18934374,  0.04454996, -0.9280221 ,  0.3478402 ],\n",
            "       [ 1.7298453 ,  0.9879368 ,  1.1640464 ,  1.1006076 , -0.10653935],\n",
            "       [-1.2029463 ,  0.28635228,  1.4155979 ,  0.11870951, -1.3141483 ],\n",
            "       [-1.1941489 , -0.18958491,  0.03413862,  1.3169426 ,  0.0806038 ],\n",
            "       [ 0.1385241 ,  1.3713038 , -1.3187183 ,  0.53152674, -2.2404997 ],\n",
            "       [ 0.56294024,  0.8122311 ,  0.3175201 ,  0.53455096,  0.9050039 ],\n",
            "       [-0.37926027,  1.7410393 ,  1.0790287 , -0.5039833 ,  0.9283062 ],\n",
            "       [ 0.9706492 , -1.3153403 ,  0.33681503,  0.8099344 , -1.2018458 ],\n",
            "       [ 1.0194312 , -0.6202479 ,  1.0818833 , -1.838974  , -0.45805007],\n",
            "       [-0.6436537 ,  0.45666698, -1.1329137 , -0.6853864 ,  0.16829035]],      dtype=float32)}}\n",
            "Bytes output\n",
            "b'\\x81\\xa6params\\x82\\xa4bias\\xc7!\\x01\\x93\\x91\\x05\\xa7float32\\xc4\\x14WP\\xba\\xbfv\\xc7\\x01\\xc0\\xef\\x0f\\x05@\\x8f\\xfb\\x9b?R\\x83\\x7f\\xbf\\xa6kernel\\xc7\\xd6\\x01\\x93\\x92\\n\\x05\\xa7float32\\xc4\\xc8\\xcbC\\x81?S\\xe3A>\\x06z6=\\xdb\\x92m\\xbf\\x1c\\x18\\xb2>\\x92k\\xdd?m\\xe9|?y\\xff\\x94?\\xb6\\xe0\\x8c?M1\\xda\\xbd%\\xfa\\x99\\xbf\\xc4\\x9c\\x92>P2\\xb5?\\xf9\\x1d\\xf3=\\x036\\xa8\\xbf\\xdf\\xd9\\x98\\xbf\\x8c\"B\\xbe\\xef\\xd4\\x0b=\\x93\\x91\\xa8?\\x9b\\x13\\xa5=C\\xd9\\r>\\xe2\\x86\\xaf?\\xc3\\xcb\\xa8\\xbf#\\x12\\x08?Yd\\x0f\\xc0\\xda\\x1c\\x10?a\\xeeO?\\xff\\x91\\xa2>U\\xd8\\x08?V\\xaeg?g.\\xc2\\xbe`\\xda\\xde?\\x9d\\x1d\\x8a?\\r\\x05\\x01\\xbfz\\xa5m?w|x?\\x12]\\xa8\\xbf\\x05s\\xac>\\xdcWO?\\x15\\xd6\\x99\\xbf\\xb9|\\x82?\\x91\\xc8\\x1e\\xbf\\'{\\x8a?\\x80c\\xeb\\xbf\\x8a\\x85\\xea\\xbe}\\xc6$\\xbfA\\xd0\\xe9>Q\\x03\\x91\\xbf|u/\\xbfNT,>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "serialization.from_bytes(params, bytes_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez2DtRVJLwuX",
        "outputId": "ee7c2430-69d7-45ea-fcb8-722c43d07599"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    params: {\n",
              "        bias: array([-1.4555768 , -2.0277991 ,  2.0790975 ,  1.2186145 , -0.99809754],\n",
              "              dtype=float32),\n",
              "        kernel: array([[ 1.0098814 ,  0.18934374,  0.04454996, -0.9280221 ,  0.3478402 ],\n",
              "               [ 1.7298453 ,  0.9879368 ,  1.1640464 ,  1.1006076 , -0.10653935],\n",
              "               [-1.2029463 ,  0.28635228,  1.4155979 ,  0.11870951, -1.3141483 ],\n",
              "               [-1.1941489 , -0.18958491,  0.03413862,  1.3169426 ,  0.0806038 ],\n",
              "               [ 0.1385241 ,  1.3713038 , -1.3187183 ,  0.53152674, -2.2404997 ],\n",
              "               [ 0.56294024,  0.8122311 ,  0.3175201 ,  0.53455096,  0.9050039 ],\n",
              "               [-0.37926027,  1.7410393 ,  1.0790287 , -0.5039833 ,  0.9283062 ],\n",
              "               [ 0.9706492 , -1.3153403 ,  0.33681503,  0.8099344 , -1.2018458 ],\n",
              "               [ 1.0194312 , -0.6202479 ,  1.0818833 , -1.838974  , -0.45805007],\n",
              "               [-0.6436537 ,  0.45666698, -1.1329137 , -0.6853864 ,  0.16829035]],\n",
              "              dtype=float32),\n",
              "    },\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전에 생성된 params을 템플릿으로 활용하여 모델 load"
      ],
      "metadata": {
        "id": "7PRCQUryMEdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining your own models"
      ],
      "metadata": {
        "id": "rjF4PlyeOhfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExplicitMLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "\n",
        "  def setup(self):\n",
        "    # we automatically know what to do with lists, dicts of submodules\n",
        "    self.layers = [nn.Dense(feat) for feat in self.features]\n",
        "    # for single submodules, we would just write:\n",
        "    # self.layer1 = nn.Dense(feat1)\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, lyr in enumerate(self.layers):\n",
        "      x = lyr(x)\n",
        "      if i != len(self.layers) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
        "x = random.uniform(key1, (4,4))\n",
        "\n",
        "model = ExplicitMLP(features=[3,4,5])\n",
        "params = model.init(key2, x)\n",
        "y = model.apply(params, x)\n",
        "\n",
        "print('initialized parameter shapes:\\n', jax.tree_util.tree_map(jnp.shape, unfreeze(params)))\n",
        "print('output:\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDCk1_NrMQDy",
        "outputId": "975b5efa-a31d-4602-c478-7c75110e171e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialized parameter shapes:\n",
            " {'params': {'layers_0': {'bias': (3,), 'kernel': (4, 3)}, 'layers_1': {'bias': (4,), 'kernel': (3, 4)}, 'layers_2': {'bias': (5,), 'kernel': (4, 5)}}}\n",
            "output:\n",
            " [[ 0.          0.          0.          0.          0.        ]\n",
            " [ 0.0072379  -0.00810348 -0.0255094   0.02151717 -0.01261241]\n",
            " [ 0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`setup()` 메서드는 서브모듈, 변수, 파라미터 등 모델에 필요한 것들을 등록하는 `__postinit__` 다음에 호출됨"
      ],
      "metadata": {
        "id": "PA47iSBbRFWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    y = model(x) # Returns an error\n",
        "except AttributeError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvlmJzjRMYgI",
        "outputId": "23cdad31-a467-42f7-f6e9-1e3f108a65dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"ExplicitMLP\" object has no attribute \"layers\". If \"layers\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 구조와 파라미터가 직접 연결되어 있지 않으므로 바로 `model(x)`를 call 할 수 없음"
      ],
      "metadata": {
        "id": "w_BPv48gQtsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, feat in enumerate(self.features):\n",
        "      x = nn.Dense(feat, name=f'layers_{i}')(x)\n",
        "      if i != len(self.features) - 1:\n",
        "        x = nn.relu(x)\n",
        "      # providing a name is optional though!\n",
        "      # the default autonames would be \"Dense_0\", \"Dense_1\", ...\n",
        "    return x\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
        "x = random.uniform(key1, (4,4))\n",
        "\n",
        "model = SimpleMLP(features=[3,4,5])\n",
        "params = model.init(key2, x)\n",
        "y = model.apply(params, x)\n",
        "\n",
        "print('initialized parameter shapes:\\n', jax.tree_util.tree_map(jnp.shape, unfreeze(params)))\n",
        "print('output:\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sav1CR1BQdUu",
        "outputId": "192a0866-7c3b-44a8-ce82-cb9c577f609b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialized parameter shapes:\n",
            " {'params': {'layers_0': {'bias': (3,), 'kernel': (4, 3)}, 'layers_1': {'bias': (4,), 'kernel': (3, 4)}, 'layers_2': {'bias': (5,), 'kernel': (4, 5)}}}\n",
            "output:\n",
            " [[ 0.          0.          0.          0.          0.        ]\n",
            " [ 0.0072379  -0.00810348 -0.0255094   0.02151717 -0.01261241]\n",
            " [ 0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델이 간단하므로 `@nn.compact` 어노테이션을 사용하여 setup 대체\n",
        "\n",
        "두 가지 방법의 차이\n",
        "- `setup`에서는 sublayer를 네이밍할 수 있고, 향후 사용을 위해 킵해둘 수 있음\n",
        "- 여러 메서드를 사용하려면 `setup`을 사용. `@nn.compact` 어노테이션은 하나의 메서드에만 허용됨"
      ],
      "metadata": {
        "id": "qNw2yJ9pRrqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDense(nn.Module):\n",
        "  features: int\n",
        "  kernel_init: Callable = nn.initializers.lecun_normal()\n",
        "  bias_init: Callable = nn.initializers.zeros_init()\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    kernel = self.param('kernel',\n",
        "                        self.kernel_init, # Initialization function\n",
        "                        (inputs.shape[-1], self.features))  # shape info.\n",
        "    y = lax.dot_general(inputs, kernel,\n",
        "                        (((inputs.ndim - 1,), (0,)), ((), ())),) # TODO Why not jnp.dot?\n",
        "    bias = self.param('bias', self.bias_init, (self.features,))\n",
        "    y = y + bias\n",
        "    return y\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
        "x = random.uniform(key1, (4,4))\n",
        "\n",
        "model = SimpleDense(features=3)\n",
        "params = model.init(key2, x)\n",
        "y = model.apply(params, x)\n",
        "\n",
        "print('initialized parameters:\\n', params)\n",
        "print('output:\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI7ceGXeRYET",
        "outputId": "bd58752d-5053-4bc9-9426-e8a168c4f23c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialized parameters:\n",
            " FrozenDict({\n",
            "    params: {\n",
            "        kernel: Array([[ 0.61506   , -0.22728713,  0.6054702 ],\n",
            "               [-0.29617992,  1.1232013 , -0.879759  ],\n",
            "               [-0.35162622,  0.3806491 ,  0.6893246 ],\n",
            "               [-0.1151355 ,  0.04567898, -1.091212  ]], dtype=float32),\n",
            "        bias: Array([0., 0., 0.], dtype=float32),\n",
            "    },\n",
            "})\n",
            "output:\n",
            " [[-0.02996203  1.102088   -0.6660265 ]\n",
            " [-0.31092793  0.63239413 -0.53678817]\n",
            " [ 0.01424009  0.9424717  -0.63561463]\n",
            " [ 0.3681896   0.3586519  -0.00459218]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dense layer 없으면 이렇게 직접 사용. `param` 함수 사용"
      ],
      "metadata": {
        "id": "vJXt3Sw2T5fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiasAdderWithRunningMean(nn.Module):\n",
        "  decay: float = 0.99\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    # easy pattern to detect if we're initializing via empty variable tree\n",
        "    is_initialized = self.has_variable('batch_stats', 'mean')\n",
        "    ra_mean = self.variable('batch_stats', 'mean',\n",
        "                            lambda s: jnp.zeros(s),\n",
        "                            x.shape[1:])\n",
        "    mean = ra_mean.value # This will either get the value or trigger init\n",
        "    bias = self.param('bias', lambda rng, shape: jnp.zeros(shape), x.shape[1:])\n",
        "    if is_initialized:\n",
        "      ra_mean.value = self.decay * ra_mean.value + (1.0 - self.decay) * jnp.mean(x, axis=0, keepdims=True)\n",
        "\n",
        "    return x - ra_mean.value + bias\n",
        "\n",
        "\n",
        "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
        "x = jnp.ones((10,5))\n",
        "model = BiasAdderWithRunningMean()\n",
        "variables = model.init(key1, x)\n",
        "print('initialized variables:\\n', variables)\n",
        "y, updated_state = model.apply(variables, x, mutable=['batch_stats'])\n",
        "print('updated state:\\n', updated_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm2CkS9uSpeg",
        "outputId": "2c1916d4-ce2d-4a0e-a035-8dd041c46618"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialized variables:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([0., 0., 0., 0., 0.], dtype=float32),\n",
            "    },\n",
            "    params: {\n",
            "        bias: Array([0., 0., 0., 0., 0.], dtype=float32),\n",
            "    },\n",
            "})\n",
            "updated state:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.01, 0.01, 0.01, 0.01, 0.01]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`variable` 변수를 사용하여 파라미터를 넘어서는 변수 선언"
      ],
      "metadata": {
        "id": "sjo5DTr1Ue78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for val in [1.0, 2.0, 3.0]:\n",
        "  x = val * jnp.ones((10,5))\n",
        "  y, updated_state = model.apply(variables, x, mutable=['batch_stats'])\n",
        "  old_state, params = variables.pop('params')\n",
        "  variables = freeze({'params': params, **updated_state})\n",
        "  print('updated state:\\n', updated_state) # Shows only the mutable part"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7XMYgFHUGHw",
        "outputId": "a246c739-16f2-442e-c87c-2d305d027d43"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updated state:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.01, 0.01, 0.01, 0.01, 0.01]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "updated state:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.0299, 0.0299, 0.0299, 0.0299, 0.0299]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "updated state:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.059601, 0.059601, 0.059601, 0.059601, 0.059601]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "@partial(jax.jit, static_argnums=(0, 1))\n",
        "def update_step(tx, apply_fn, x, opt_state, params, state):\n",
        "\n",
        "  def loss(params):\n",
        "    y, updated_state = apply_fn({'params': params, **state},\n",
        "                                x, mutable=list(state.keys()))\n",
        "    l = ((x - y) ** 2).sum()\n",
        "    return l, updated_state\n",
        "\n",
        "  (l, state), grads = jax.value_and_grad(loss, has_aux=True)(params)\n",
        "  updates, opt_state = tx.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return opt_state, params, state\n",
        "\n",
        "x = jnp.ones((10,5))\n",
        "variables = model.init(random.PRNGKey(0), x)\n",
        "state, params = variables.pop('params')\n",
        "del variables\n",
        "tx = optax.sgd(learning_rate=0.02)\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for _ in range(3):\n",
        "  opt_state, params, state = update_step(tx, model.apply, x, opt_state, params, state)\n",
        "  print('Updated state: ', state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urbXvSsiXBHS",
        "outputId": "616c206b-4f50-4539-a10f-d9d92c052db8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated state:  FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.01, 0.01, 0.01, 0.01, 0.01]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "Updated state:  FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.0199, 0.0199, 0.0199, 0.0199, 0.0199]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "Updated state:  FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: Array([[0.029701, 0.029701, 0.029701, 0.029701, 0.029701]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Managing Parameters and State"
      ],
      "metadata": {
        "id": "epcgH37Rxm9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiasAdderWithRunningMean(nn.Module):\n",
        "  momentum: float = 0.9\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    is_initialized = self.has_variable('batch_stats', 'mean')\n",
        "    mean = self.variable('batch_stats', 'mean', jnp.zeros, x.shape[1:])\n",
        "    bias = self.param('bias', lambda rng, shape: jnp.zeros(shape), x.shape[1:])\n",
        "    if is_initialized:\n",
        "      mean.value = (self.momentum * mean.value +\n",
        "                    (1.0 - self.momentum) * jnp.mean(x, axis=0, keepdims=True))\n",
        "    return mean.value + bias"
      ],
      "metadata": {
        "id": "gKU74RrgxsYG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "상태변수와 최적화할 매개변수를 따로 관리해야 한다는 점이 매우 까다로움"
      ],
      "metadata": {
        "id": "QEYSlnE4yqCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_step(apply_fn, x, opt_state, params, state):\n",
        "  def loss(params):\n",
        "    y, updated_state = apply_fn({'params': params, **state},\n",
        "                                x, mutable=list(state.keys()))\n",
        "    l = ((x - y) ** 2).sum() # Replace with your loss here.\n",
        "    return l, updated_state\n",
        "\n",
        "  (l, updated_state), grads = jax.value_and_grad(\n",
        "      loss, has_aux=True)(params)\n",
        "  updates, opt_state = tx.update(grads, opt_state)  # Defined below.\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return opt_state, params, updated_state"
      ],
      "metadata": {
        "id": "FIwrc94jyQ4_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = random.normal(key1, (10,))\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "i42gLuUQcCC7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiasAdderWithRunningMean()\n",
        "variables = model.init(random.PRNGKey(0), dummy_input)\n",
        "# Split state and params (which are updated by optimizer).\n",
        "state, params = variables.pop('params')\n",
        "del variables  # Delete variables to avoid wasting resources\n",
        "tx = optax.sgd(learning_rate=0.02)\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for _ in range(num_epochs):\n",
        "  opt_state, params, state = update_step(\n",
        "      model.apply, dummy_input, opt_state, params, state)"
      ],
      "metadata": {
        "id": "kDgV_dXszVZ8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `vmap` accross the batch dimension "
      ],
      "metadata": {
        "id": "AU8aoYB70URv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "batchnorm 을 사용하기 위해 두가지 변화 필요\n",
        "1. 모델 정의 시 batch axis 네이밍. 커스터마이즈할 때는 axis_name 인자를 lax.pmean()에 직접 전달해야할 수도 있음.\n",
        "2. 트레이닝 코드의 vmap에도 같은 이름을 지정해주어야 함"
      ],
      "metadata": {
        "id": "DBXK65Richdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  hidden_size: int\n",
        "  out_size: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, train=False):\n",
        "    norm = partial(\n",
        "        nn.BatchNorm,\n",
        "        use_running_average=not train,\n",
        "        momentum=0.9,\n",
        "        epsilon=1e-5,\n",
        "        axis_name=\"batch\", # Name batch dim\n",
        "    )\n",
        "\n",
        "    x = nn.Dense(self.hidden_size)(x)\n",
        "    x = norm()(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(self.hidden_size)(x)\n",
        "    x = norm()(x)\n",
        "    x = nn.relu(x)\n",
        "    y = nn.Dense(self.out_size)(x)\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "0j9f3u9zdbcB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_step(apply_fn, x, opt_state, params, state):\n",
        "  def loss(params):\n",
        "    y, updated_state = apply_fn({'params': params, **state},\n",
        "                                x, mutable=list(state.keys()))\n",
        "    l = ((x - y) ** 2).sum() # Replace with your loss here.\n",
        "    return l, updated_state\n",
        "\n",
        "  (l, updated_state), grads = jax.value_and_grad(\n",
        "      loss, has_aux=True)(params)\n",
        "  updates, opt_state = tx.update(grads, opt_state)  # Defined below.\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return opt_state, params, updated_state"
      ],
      "metadata": {
        "id": "F--u3s3d_zFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 아래 비교"
      ],
      "metadata": {
        "id": "EqmZUuHC_2RR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_step(apply_fn, x_batch, y_batch, opt_state, params, state):\n",
        "\n",
        "  def batch_loss(params):\n",
        "    def loss_fn(x, y):\n",
        "      pred, updated_state = apply_fn(\n",
        "        {'params': params, **state},\n",
        "        x, mutable=list(state.keys())\n",
        "      )\n",
        "      return (pred - y) ** 2, updated_state\n",
        "\n",
        "    loss, updated_state = jax.vmap(\n",
        "      loss_fn, out_axes=(0, None),  # Do not vmap `updated_state`.\n",
        "      axis_name='batch'  # Name batch dim\n",
        "    )(x_batch, y_batch)  # vmap only `x`, `y`, but not `state`.\n",
        "    return jnp.mean(loss), updated_state\n",
        "\n",
        "  (loss, updated_state), grads = jax.value_and_grad(\n",
        "    batch_loss, has_aux=True\n",
        "  )(params)\n",
        "\n",
        "  updates, opt_state = tx.update(grads, opt_state)  # Defined below.\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return opt_state, params, updated_state, loss"
      ],
      "metadata": {
        "id": "fuk1tR5jdvW-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss_fn을 vmap. update_state는 vmap하지 않으므로 out_axes (0, None)"
      ],
      "metadata": {
        "id": "CVPpL-XqCEiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiasAdderWithRunningMean()\n",
        "variables = model.init(random.PRNGKey(0), dummy_input)\n",
        "# Split state and params (which are updated by optimizer).\n",
        "state, params = variables.pop('params')\n",
        "del variables  # Delete variables to avoid wasting resources\n",
        "tx = optax.sgd(learning_rate=0.02)\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for _ in range(num_epochs):\n",
        "  opt_state, params, state = update_step(\n",
        "      model.apply, dummy_input, opt_state, params, state)"
      ],
      "metadata": {
        "id": "VRuU7athC3uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 아래 비교"
      ],
      "metadata": {
        "id": "jRq2CKepC4fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(hidden_size=10, out_size=1)\n",
        "variables = model.init(random.PRNGKey(0), dummy_input)\n",
        "# Split state and params (which are updated by optimizer).\n",
        "state, params = variables.pop('params')\n",
        "del variables  # Delete variables to avoid wasting resources\n",
        "tx = optax.sgd(learning_rate=0.02)\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for _ in range(num_epochs):\n",
        "  opt_state, params, state, loss = update_step(\n",
        "      model.apply, x_samples, y_samples, opt_state, params, state)"
      ],
      "metadata": {
        "id": "Q0rbyYbhd86Z"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `setup` vs. `compact`\n",
        "\n",
        "- setup -> 명시적. pytorch와 유사. pytorch에서 포팅하기 쉽고 여러 포워드패스를 정의할 수 있음...?\n",
        "- compact -> 인라인? 단일 메서드에 전체 포워드 패스를 명시함. 짧은 코드. 코드가 좀 더 수학적 표현에 가까워짐. 파라미터가 입력 변수의 shape에 의해 결정되어도 됨, 그러나 setup에서는 불가능."
      ],
      "metadata": {
        "id": "97xrXoL_d-Dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dealing with Flax Module arguments\n",
        "\n",
        "Flax linen에선 모듈 인수를 dataclass 속성 또는 보통 `__ call__` 메서드의 인수로 구분가능\n",
        "\n",
        "- 완전히 고정적인 속성(kernel initializer의 선택, 출력 feature 수)는 하이퍼파라미터이며 따라서 dataclass 속성으로 정의되어야 함. 일반적으로 다른 하이퍼파라미터를 가진 두 모듈은 share할 수 없음.\n",
        "- 동적 속성(입력, mode switch) 등은 `__call__`이나 다른 속성으로 전달되어야 함"
      ],
      "metadata": {
        "id": "JVs1U8tQDaOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그러나 명확하지 않은 케이스들도 있음. dropout 모듈의 경우\n",
        "\n",
        "아래의 경우는 명확\n",
        "- 하이퍼파라미터: the dropout rate, dropout mask가 생성되는 축\n",
        "- call time 인자: dropout을 사용하여 maked되는 입력. random masking을 위해 사용되는 rng\n",
        "\n",
        "그러나 `deterministic` 속성은 모호함.\n"
      ],
      "metadata": {
        "id": "k-7XKnk4Fwun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터로 간주하는 경우\n",
        "from functools import partial\n",
        "from flax import linen as nn\n",
        "\n",
        "class ResidualModel(nn.Module):\n",
        "  drop_rate: float\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, *, train):\n",
        "    dropout = partial(nn.Dropout, rate=self.drop_rate, deterministic=not train)\n",
        "    for i in range(10):\n",
        "      x += ResidualBlock(dropout=dropout, ...)(x)"
      ],
      "metadata": {
        "id": "VJRoCeSCHxrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메서드 인자로 간주하는 경우\n",
        "class SomeModule(nn.Module):\n",
        "  drop_rate: float\n",
        "\n",
        "  def setup(self):\n",
        "    self.dropout = nn.Dropout(rate=self.drop_rate)\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, *, train):\n",
        "    # ...\n",
        "    x = self.dropout(x, deterministic=not train)\n",
        "    # ..."
      ],
      "metadata": {
        "id": "XHLZ-JXVIXlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "따라서 아래와 같이 처리.\n",
        "이 예제에서 nn.merge_param은 self.deterministic 또는 deterministic 중 하나만 설정되지만 둘 다 설정되지는 않도록 함.\n",
        "\n"
      ],
      "metadata": {
        "id": "rXkOX9ctI6tP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDropout(nn.Module):\n",
        "  drop_rate: float\n",
        "  deterministic: Optional[bool] = None\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, deterministic=None):\n",
        "    deterministic = nn.merge_param('deterministic', self.deterministic, deterministic)\n",
        "    # ..."
      ],
      "metadata": {
        "id": "3-4SmHsBI728"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}