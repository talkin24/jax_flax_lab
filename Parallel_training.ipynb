{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmmGMNWE0iPbTewQiOwrtt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talkin24/jaxflax_lab/blob/main/Parallel_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensembling on multiple devices"
      ],
      "metadata": {
        "id": "SaxTBxAqXfY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앙상블의 크기가 사용 가능한 디바이스 수와 동일한 MNIST 데이터 세트에서 CNN의 앙상블을 훈련하는 방법을 보여드리겠습니다. 간단히 설명하면 다음과 같습니다:\n",
        "\n",
        "- `jax.pmap()`을 사용하여 여러 함수를 병렬로 만듭니다,\n",
        "\n",
        "- 랜덤 시드를 분할하여 다른 매개변수 초기화를 얻습니다,\n",
        "\n",
        "- 입력을 복제하고 필요한 경우 출력을 복제 해제합니다,\n",
        "\n",
        "- 예측을 계산하기 위해 여러 기기에서 평균 확률을 계산합니다.\n",
        "\n",
        "이 하우투에서는 임포트, CNN 모듈, 메트릭 계산과 같은 일부 코드를 생략했지만 이러한 코드는 MNIST 예제에서 찾을 수 있습니다."
      ],
      "metadata": {
        "id": "RaB0xEX0ZSha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parallel functions\n",
        "\n",
        "먼저 모델의 초기 파라미터를 검색하는 `create_train_state()`의 병렬 버전을 생성합니다. 이 작업은 `jax.pmap()`을 사용하여 수행합니다. 함수를 \"pmap\"하는 효과는 함수를 XLA로 컴파일하지만(jax.jit()와 유사), XLA 디바이스(예: GPU/TPU)에서 병렬로 실행하는 것입니다."
      ],
      "metadata": {
        "id": "tiENrVX8ZiT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single-model\n",
        "def create_train_state(rng, learning_rate, momentum):\n",
        "  cnn = CNN()\n",
        "  params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
        "  tx = optax.sgd(learning_rate, momentum)\n",
        "  return train_state.TrainState.create(\n",
        "      apply_fn=cnn.apply, params=params, tx=tx)\n",
        "  \n",
        "\n",
        "# Ensemble\n",
        "@functools.partial(jax.pmap, static_broadcasted_argnums=(1, 2)) #####\n",
        "def create_train_state(rng, learning_rate, momentum):\n",
        "  cnn = CNN()\n",
        "  params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
        "  tx = optax.sgd(learning_rate, momentum)\n",
        "  return train_state.TrainState.create(\n",
        "      apply_fn=cnn.apply, params=params, tx=tx)"
      ],
      "metadata": {
        "id": "-zvyq-nQZpZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 단일 모델 코드의 경우 `jax.jit()`를 사용하여 모델을 느리게 초기화합니다. \n",
        "\n",
        "앙상블의 경우 `jax.pmap()`은 기본적으로 제공된 인수 `rng`의 첫 번째 축에 매핑되므로 나중에 이 함수를 호출할 때 각 디바이스에 대해 다른 값을 제공해야 합니다.\n",
        "\n",
        "또한 `learning_rate`와 `momentum`을 정적 인자로 지정하여 추상적인 모양이 아닌 이 인자의 구체적인 값을 사용하도록 지정한 점에 유의하세요. 이는 제공된 인수가 스칼라 값이기 때문에 필요합니다. \n",
        "\n",
        "다음으로 `apply_model()` 및 `update_model()` 함수에 대해서도 동일한 작업을 수행합니다. \n",
        "\n",
        "앙상블에서 예측을 계산하기 위해 개별 확률의 평균을 취합니다. `jax.lax.pmean()`을 사용하여 여러 기기에서 평균을 계산합니다. 이를 위해서는 `jax.pmap()` 및 `jax.lax.pmean()` 모두에 axis_name을 지정해야 합니다."
      ],
      "metadata": {
        "id": "5-cUTwCqaPCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Single-model\n",
        "@jax.jit #####\n",
        "def apply_model(state, images, labels):\n",
        "  def loss_fn(params):\n",
        "    logits = CNN().apply({'params': params}, images)\n",
        "    one_hot = jax.nn.one_hot(labels, 10)\n",
        "    loss = optax.softmax_cross_entropy(logits=logits, labels=one_hot).mean()\n",
        "    return loss, logits\n",
        "\n",
        "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (loss, logits), grads = grad_fn(state.params)\n",
        "\n",
        "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels) #####\n",
        "  return grads, loss, accuracy\n",
        "\n",
        "@jax.jit #####\n",
        "def update_model(state, grads):\n",
        "  return state.apply_gradients(grads=grads)\n",
        "\n",
        "\n",
        "# Ensemble\n",
        "@functools.partial(jax.pmap, axis_name='ensemble') #####\n",
        "def apply_model(state, images, labels):\n",
        "  def loss_fn(params):\n",
        "    logits = CNN().apply({'params': params}, images)\n",
        "    one_hot = jax.nn.one_hot(labels, 10)\n",
        "    loss = optax.softmax_cross_entropy(logits=logits, labels=one_hot).mean()\n",
        "    return loss, logits\n",
        "\n",
        "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (loss, logits), grads = grad_fn(state.params)\n",
        "  probs = jax.lax.pmean(jax.nn.softmax(logits), axis_name='ensemble') #####\n",
        "  accuracy = jnp.mean(jnp.argmax(probs, -1) == labels) #####\n",
        "  return grads, loss, accuracy\n",
        "\n",
        "@jax.pmap #####\n",
        "def update_model(state, grads):\n",
        "  return state.apply_gradients(grads=grads)"
      ],
      "metadata": {
        "id": "zRXl5353a1UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Ensemble\n",
        "\n",
        "다음으로 `train_epoch()` 함수를 변환합니다.\n",
        "\n",
        "위에서 pmapped 함수를 호출할 때 필요한 경우 모든 디바이스에 대한 인수를 복제하고 반환값의 중복을 제거하는 작업을 주로 처리해야 합니다."
      ],
      "metadata": {
        "id": "NGJNAGcOOFYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single-model\n",
        "def train_epoch(state, train_ds, batch_size, rng):\n",
        "  train_ds_size = len(train_ds['image'])\n",
        "  steps_per_epoch = train_ds_size // batch_size\n",
        "\n",
        "  perms = jax.random.permutation(rng, len(train_ds['image']))\n",
        "  perms = perms[:steps_per_epoch * batch_size]\n",
        "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
        "\n",
        "  epoch_loss = []\n",
        "  epoch_accuracy = []\n",
        "\n",
        "  for perm in perms:\n",
        "    batch_images = train_ds['image'][perm, ...] #####\n",
        "    batch_labels = train_ds['label'][perm, ...] #####\n",
        "    grads, loss, accuracy = apply_model(state, batch_images, batch_labels)\n",
        "    state = update_model(state, grads)\n",
        "    epoch_loss.append(loss) #####\n",
        "    epoch_accuracy.append(accuracy) #####\n",
        "  train_loss = np.mean(epoch_loss)\n",
        "  train_accuracy = np.mean(epoch_accuracy)\n",
        "  return state, train_loss, train_accuracy\n",
        "\n",
        "\n",
        "# Ensemble\n",
        "def train_epoch(state, train_ds, batch_size, rng):\n",
        "  train_ds_size = len(train_ds['image'])\n",
        "  steps_per_epoch = train_ds_size // batch_size\n",
        "\n",
        "  perms = jax.random.permutation(rng, len(train_ds['image']))\n",
        "  perms = perms[:steps_per_epoch * batch_size]\n",
        "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
        "\n",
        "  epoch_loss = []\n",
        "  epoch_accuracy = []\n",
        "\n",
        "  for perm in perms:\n",
        "    batch_images = jax_utils.replicate(train_ds['image'][perm, ...]) #####\n",
        "    batch_labels = jax_utils.replicate(train_ds['label'][perm, ...]) #####\n",
        "    grads, loss, accuracy = apply_model(state, batch_images, batch_labels)\n",
        "    state = update_model(state, grads)\n",
        "    epoch_loss.append(jax_utils.unreplicate(loss)) #####\n",
        "    epoch_accuracy.append(jax_utils.unreplicate(accuracy)) #####\n",
        "  train_loss = np.mean(epoch_loss)\n",
        "  train_accuracy = np.mean(epoch_accuracy)\n",
        "  return state, train_loss, train_accuracy"
      ],
      "metadata": {
        "id": "Ty8H1NVUOXL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "보시다시피 `state`와 관련된 로직을 변경할 필요가 없습니다. \n",
        "\n",
        "아래 훈련 코드에서 볼 수 있듯이 train state는 이미 복제되어 있으므로 `train_step()`에 전달하면 `train_step()`이 pmap되어 있기 때문에 정상적으로 작동하기 때문입니다. 그러나 훈련 데이터 세트는 아직 복제되지 않았으므로 여기서 리플리케이션을 수행합니다. 전체 train 데이터 집합을 복제하는 것은 너무 많은 메모리를 사용하므로 배치 수준에서 수행합니다.\n",
        "\n",
        "이제 실제 훈련 로직을 다시 작성할 수 있습니다. 이는 두 가지 간단한 변경 사항으로 구성됩니다. RNG를 `create_train_state()`에 전달할 때 복제되는지 확인하는 것과 전체 데이터 세트에 대해 직접 이 작업을 수행할 수 있도록 훈련 데이터 세트보다 훨씬 작은 테스트 데이터 세트를 리플리케이트하는 것입니다."
      ],
      "metadata": {
        "id": "w9fgkrSlPTra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single-model\n",
        "train_ds, test_ds = get_datasets()\n",
        "\n",
        "rng = jax.random.PRNGKey(0)\n",
        "\n",
        "rng, init_rng = jax.random.split(rng)\n",
        "state = create_train_state(init_rng, learning_rate, momentum) #####\n",
        "\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  rng, input_rng = jax.random.split(rng)\n",
        "  state, train_loss, train_accuracy = train_epoch(\n",
        "      state, train_ds, batch_size, input_rng)\n",
        "\n",
        "  _, test_loss, test_accuracy = apply_model( #####\n",
        "      state, test_ds['image'], test_ds['label']) #####\n",
        "\n",
        "  logging.info(\n",
        "      'epoch:% 3d, train_loss: %.4f, train_accuracy: %.2f, '\n",
        "      'test_loss: %.4f, test_accuracy: %.2f'\n",
        "      % (epoch, train_loss, train_accuracy * 100, test_loss,\n",
        "         test_accuracy * 100))\n",
        "\n",
        "\n",
        "# Ensemble\n",
        "train_ds, test_ds = get_datasets()\n",
        "test_ds = jax_utils.replicate(test_ds) #####\n",
        "rng = jax.random.PRNGKey(0)\n",
        "\n",
        "rng, init_rng = jax.random.split(rng)\n",
        "state = create_train_state(jax.random.split(init_rng, jax.device_count()), #####\n",
        "                           learning_rate, momentum) #####\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  rng, input_rng = jax.random.split(rng)\n",
        "  state, train_loss, train_accuracy = train_epoch(\n",
        "      state, train_ds, batch_size, input_rng)\n",
        "\n",
        "  _, test_loss, test_accuracy = jax_utils.unreplicate( #####\n",
        "      apply_model(state, test_ds['image'], test_ds['label'])) #####\n",
        "\n",
        "  logging.info(\n",
        "      'epoch:% 3d, train_loss: %.4f, train_accuracy: %.2f, '\n",
        "      'test_loss: %.4f, test_accuracy: %.2f'\n",
        "      % (epoch, train_loss, train_accuracy * 100, test_loss,\n",
        "         test_accuracy * 100))"
      ],
      "metadata": {
        "id": "RdETw_CXPvtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scale up Flax Modules on multiple devices with `pjit`\n",
        "\n",
        "이 가이드에서는 JAX의 `pjit` 및 `flax.linen.spmd`를 사용하여 여러 장치 및 호스트에서 Flax 모듈을 확장하는 방법을 보여줍니다."
      ],
      "metadata": {
        "id": "6hCou_VkQ5rD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flax and `pjit`\n",
        "\n",
        "`jxa.experimental.pjit`은 JAX 계산을 자동으로 컴파일하고 확장하는 방법을 제공합니다. `pjit`에는 다음과 같은 이점이 있습니다:\n",
        "\n",
        "- `pjit`은 `jax.jit`과 유사한 인터페이스를 가지고 있으며 컴파일해야 하는 함수의 데코레이터로 작동합니다.\n",
        "\n",
        "- `pjit`을 사용하면 단일 기기에서 실행되는 것처럼 코드를 작성할 수 있으며, 단일 프로그램 다중 데이터(SPMD) 패러다임을 사용하여 여러 기기에서 자동으로 컴파일 및 실행됩니다.\n",
        "\n",
        "- `pjit`을 사용하면 코드의 입력과 출력을 여러 기기에서 분할하는 방법을 명시할 수 있으며 컴파일러가 그 방법을 알아서 처리합니다: 1) 내부의 모든 것을 분할하고, 2) 디바이스 간 통신을 컴파일합니다.\n",
        "\n",
        "\n",
        "Flax는 `Flax Module`에서 `pjit`을 사용하는 데 도움이 되는 다음과 같은 몇 가지 기능을 제공합니다:\n",
        "\n",
        "1. `flax.linen.Module`을 정의할 때 데이터의 파티션을 지정하는 인터페이스.\n",
        "\n",
        "2. `pjit` 실행에 필요한 파티션 정보를 생성하는 유틸리티 함수.\n",
        "\n",
        "3. \"logical axis annotations\"이라는 축 이름을 사용자 정의하는 인터페이스로, 모듈 코드와 파티션 계획을 분리하여 다양한 파티션 레이아웃을 더 쉽게 실험할 수 있습니다."
      ],
      "metadata": {
        "id": "P_VkC_sXQ-zd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "6AFAt2WlRr61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Once Flax v0.6.4 is released, use `pip3 install flax`.\n",
        "! pip3 install -qq \"git+https://github.com/google/flax.git@main#egg=flax\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRT6hLptRv6D",
        "outputId": "37077f03-c43a-4436-e5e8-947cc0ace0d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports "
      ],
      "metadata": {
        "id": "QK8jFlTxRxZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'"
      ],
      "metadata": {
        "id": "3uZZsJn-R729"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import numpy as np\n",
        "import jax\n",
        "\n",
        "from jax import lax, random, numpy as jnp\n",
        "\n",
        "import flax\n",
        "from flax import struct, traverse_util, linen as nn\n",
        "from flax.linen import spmd # Flax Linen SPMD.\n",
        "from flax.core import freeze, unfreeze\n",
        "from flax.training import train_state, checkpoints\n",
        "\n",
        "import optax # Optax for common losses and optimizers. "
      ],
      "metadata": {
        "id": "WOrg5ALTR8Fs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 2x4 디바이스 메시(8개 디바이스)를 시작합니다(TPU v3-8의 레이아웃과 동일).\n",
        "\n",
        "2. 각 축에 이름을 붙입니다. 축 이름에 주석을 다는 일반적인 방법은 `('data', 'model')`이며, 여기서 '데이터'는 다음과 같습니다:\n",
        "\n",
        "- `data`: 입력 및 활성화의 배치 차원에 대한 데이터 병렬 샤딩에 사용되는 메시 차원입니다.\n",
        "\n",
        "- `model`: 여러 기기에서 모델의 매개변수를 샤딩하는 데 사용되는 메시 차원입니다."
      ],
      "metadata": {
        "id": "7FShB22wS_Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax.experimental.pjit import pjit, with_sharding_constraint\n",
        "from jax.sharding import Mesh, PartitionSpec\n",
        "from jax.experimental import mesh_utils\n",
        "\n",
        "# Start a device mesh.\n",
        "device_mesh = mesh_utils.create_device_mesh((2, 4))\n",
        "print(device_mesh)\n",
        "# Annotate each axis with a name.\n",
        "mesh = Mesh(devices=device_mesh, axis_names=('data', 'model'))\n",
        "mesh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbMQ7ZCDR9bV",
        "outputId": "7006fb49-5d32-4b8e-d692-04650f36151b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[CpuDevice(id=0) CpuDevice(id=1) CpuDevice(id=2) CpuDevice(id=3)]\n",
            " [CpuDevice(id=4) CpuDevice(id=5) CpuDevice(id=6) CpuDevice(id=7)]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mesh(device_ids=array([[0, 1, 2, 3],\n",
              "       [4, 5, 6, 7]]), axis_names=('data', 'model'))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a layer\n",
        "\n",
        "모델을 정의하기 전에 dot product를 위한 두 개의 매개변수 `W1`과 `W2`를 생성하고 그 사이에 `jax.nn.relu`(ReLU) 활성화 함수를 사용하는 `DotReluDot`이라는 예제 레이어를 생성합니다(`flax.linen.Module`을 서브클래스화 함으로써).\n",
        "\n",
        "`pjit`에서 이 레이어를 효율적으로 사용하려면 다음 API를 적용하여 매개변수와 중간 변수에 올바르게 주석을 달아야 합니다:\n",
        "\n",
        "1. 매개변수 `W1` 및 `W2`를 생성할 때 `flax.linen.with_partitioning`을 사용하여 이니셜라이저 함수를 decorate하세요.\n",
        "\n",
        "2. 이상적인 제약 조건이 알려진 경우 `pjit.with_sharding_constraint`를 적용하여 `y` 및 `z`와 같은 중간 변수에 주석을 달아 특정 샤딩 패턴을 `pjit`에서 강제로 적용합니다.\n",
        "\n",
        "- 이 단계는 선택 사항이지만 때때로 auto-SPMD가 효율적으로 파티셔닝하는 데 도움이 될 수 있습니다. 아래 예제에서는 이 호출이 필요하지 않은데, 이는 `pjit`이 `y`와 `z`에 대해 동일한 샤딩 레이아웃을 알아내기 때문입니다."
      ],
      "metadata": {
        "id": "BMvrI0gfS9pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DotReluDot(nn.Module):\n",
        "  depth: int\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    W1 = self.param(\n",
        "        'W1', \n",
        "        nn.with_partitioning(nn.initializers.xavier_normal(), (None, 'model')),\n",
        "        (x.shape[-1], self.depth))\n",
        "\n",
        "    y = jax.nn.relu(jnp.dot(x, W1))\n",
        "    # Force a local sharding annotation.\n",
        "    y = with_sharding_constraint(y, PartitionSpec('data', 'model'))\n",
        "\n",
        "    W2 = self.param(\n",
        "        'W2', \n",
        "        nn.with_partitioning(nn.initializers.xavier_normal(), ('model', None)),\n",
        "        (self.depth, x.shape[-1]))\n",
        "\n",
        "    z = jnp.dot(y, W2)\n",
        "    # Force a local sharding annotation.\n",
        "    z = with_sharding_constraint(z, PartitionSpec('data', None))\n",
        "\n",
        "    # Return a tuple to conform with the API `flax.linen.scan` as shown in the cell below.\n",
        "    return z, None"
      ],
      "metadata": {
        "id": "rYJ4byIZTaMp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`'data'`, `'model'` 또는 `None`과 같은 디바이스 축 이름은 `flax.linen.with_partitioning`과 `pjit_with_sharding_constraint` API 호출에 모두 전달됩니다. 이는 이 데이터의 각 차원을 디바이스 메시 차원 중 하나에 걸쳐 샤딩하거나 전혀 샤딩하지 않는 방식을 나타냅니다.\n",
        "\n",
        "예를 들어\n",
        "\n",
        "- shape `(x.shape[-1], self.depth)`으로 `W1`을 정의하고 주석을 `(None, 'model')`로 지정하는 경우:\n",
        "\n",
        "  - 첫 번째 차원(길이 `x.shape[-1]`)은 모든 기기에서 복제됩니다.\n",
        "\n",
        "  - 두 번째 차원(길이 `self.depth`)은 디바이스 메시의 `model` 축에 걸쳐 샤딩됩니다. 즉, `W1`은 이 차원에서 `(0, 4)`, `(1, 5)`, `(2, 6)`, `(3, 7)` 장치에서 4방향으로 샤드됩니다.\n",
        "\n",
        "- 출력 z에 `('data', None)`으로 주석을 달 때:\n",
        "\n",
        "  - 첫 번째 차원인 배치 차원이 `'data'` 축에 걸쳐 샤드됩니다. 즉, 배치의 절반은 장치 `0-3`(처음 4개의 장치)에서 처리되고 나머지 절반은 장치 `4-7`(나머지 4개의 장치)에서 처리됩니다.\n",
        "\n",
        "  - 두 번째 차원인 데이터 깊이 차원은 모든 디바이스에서 복제됩니다."
      ],
      "metadata": {
        "id": "E_Ck1QigUu6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a model with `flax.linen.scan` lifted transformation\n",
        "\n",
        "이 가이드에서는 `flax.linen.scan`을 사용하여 `scan`과 같은 Flax lifed transforms이 JAX `pjit`과 함께 작동하는 방법을 보여줍니다.\n",
        "\n",
        "`DotReluDot`을 생성한 후 `MLP` 모델을 (`flax.linen.Module`을 서브클래스화하여) `DotReluDot`의 여러 레이어로 정의합니다.\n",
        "\n",
        "동일한 레이어를 복제하려면 `flax.linen.scan` 또는 for-loop를 사용할 수 있습니다:\n",
        "\n",
        "- `flax.linen.scan`은 더 빠른 컴파일 시간을 제공할 수 있습니다.\n",
        "\n",
        "- 런타임에는 for-loop가 더 빠를 수 있습니다.\n",
        "\n",
        "아래 코드는 두 가지 방법을 모두 적용하는 방법을 보여줍니다.\n",
        "\n",
        "참고: `flax.linen.scan`에는 매개변수에 대한 또 다른 차원(`scan`이 적용되는 차원)이 있습니다. 이 차원의 파티션에 주석을 달려면 `metadata_params` 인수를 사용해야 합니다. `DotReluDot`(a sub-`Module`) 내부의 매개변수는 이미 `model` 축을 따라 분할되어 있으므로 여기서는 모델 차원에 걸쳐 여러 레이어를 분할할 필요가 없으므로 `None`으로 표시해야 합니다."
      ],
      "metadata": {
        "id": "jQXempS8ULZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  num_layers: int\n",
        "  depth: int\n",
        "  use_scan: bool\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    if self.use_scan:\n",
        "      x, _ = nn.scan(DotReluDot, length=self.num_layers, \n",
        "                     variable_axes={\"params\": 0},\n",
        "                     split_rngs={\"params\": True},\n",
        "                     metadata_params={nn.PARTITION_NAME: None}\n",
        "                     )(self.depth)(x)\n",
        "    else:\n",
        "      for i in range(self.num_layers):\n",
        "        x, _ = DotReluDot(self.depth)(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "UOw1aasCXPDo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify sharding (includes initialization and `TrainState` creation)\n",
        "\n",
        "다음으로, `pjit`이 입력 및 출력 데이터의 어노테이션으로 수신해야 하는 `jax.sharding.PartitionSpec`을 생성합니다. `PartitionSpec`은 2x4 메시에서 2축의 튜플입니다."
      ],
      "metadata": {
        "id": "1IMp3E_9XRFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specify the input\n",
        "\n",
        "데이터 병렬 처리의 경우, 배치 축을 `'data'`로 표시하여 `'data'` 축 전체에 배치 입력 `x`를 샤드할 수 있습니다:\n"
      ],
      "metadata": {
        "id": "grUj9sQmX0hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_spec = PartitionSpec('data', None)  # dimensions: (batch, length)\n",
        "x_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRTo8JGwYFSF",
        "outputId": "08d738e9-8ff6-4439-8dd7-6441a36d142e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PartitionSpec('data', None)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a `PartitionSpec` for the output\n",
        "\n",
        "그런 다음, 출력에 대한 `PartitionSpec`을 생성하고 실제 출력을 참조로 사용해야 합니다.\n",
        "\n",
        "1. 모델을 인스턴스화합니다.\n",
        "\n",
        "2. `jax.eval_shape`를 사용하여 `model.init`을 추상적으로 평가합니다.\n",
        "\n",
        "3. `flax.linen.get_partition_spec`을 사용하여 `PartitionSpec`을 자동으로 생성합니다.\n",
        "\n",
        "아래 코드는 초기화 및 훈련 단계를 수행하기 위해 `flax.training.train_state`를 사용하는 경우 출력 사양을 얻는 방법을 보여 주며, 이 경우 `pjit`된 함수는 `TrainState`를 출력합니다.\n",
        "\n",
        "(더 간단한 경우에는 `variables = model.init(k, x)`와 같이 변수 딕셔너리를 `pjit`된 함수의 출력으로 선택할 수도 있습니다. 이것도 작동합니다.)"
      ],
      "metadata": {
        "id": "TNHEKpkcYG2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP hyperparameters.\n",
        "BATCH, LAYERS, DEPTH, USE_SCAN = 8, 4, 1024, True\n",
        "# Create fake inputs.\n",
        "x = jnp.ones((BATCH, DEPTH))\n",
        "# Initialize a PRNG key.\n",
        "k = random.PRNGKey(0)\n",
        "\n",
        "# Create an Optax optimizer.\n",
        "optimizer = optax.adam(learning_rate=0.001)\n",
        "# Instantiate the model.\n",
        "model = MLP(LAYERS, DEPTH, USE_SCAN)\n",
        "\n",
        "# A functional way of model initialization.\n",
        "def init_fn(k, x, model, optimizer):\n",
        "  variables = model.init(k, x) # Initialize the model.\n",
        "  state = train_state.TrainState.create( # Create a `TrainState`.\n",
        "    apply_fn=model.apply,\n",
        "    params=variables['params'],\n",
        "    tx=optimizer)\n",
        "  return state\n",
        "\n",
        "with mesh:\n",
        "  # Create an abstract closure to wrap the function before feeding it in\n",
        "  # because `jax.eval_shape` only takes pytrees as arguments`.\n",
        "  abstract_variables = jax.eval_shape(\n",
        "      functools.partial(init_fn, model=model, optimizer=optimizer), k, x)\n",
        "# This `state_spec` has the same pytree structure as the output\n",
        "# of the `init_fn`.\n",
        "state_spec = nn.get_partition_spec(abstract_variables)\n",
        "state_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhSRpLHnYkb6",
        "outputId": "3d5a45c5-03e3-41ab-949b-d7febb067a41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainState(step=PartitionSpec(), apply_fn=<bound method Module.apply of MLP(\n",
              "    # attributes\n",
              "    num_layers = 4\n",
              "    depth = 1024\n",
              "    use_scan = True\n",
              ")>, params=FrozenDict({\n",
              "    ScanDotReluDot_0: {\n",
              "        W1: PartitionSpec(None, None, 'model'),\n",
              "        W2: PartitionSpec(None, 'model', None),\n",
              "    },\n",
              "}), tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7f0c8c2831c0>, update=<function chain.<locals>.update_fn at 0x7f0c8c283370>), opt_state=(ScaleByAdamState(count=PartitionSpec(), mu=FrozenDict({\n",
              "    ScanDotReluDot_0: {\n",
              "        W1: PartitionSpec(None, None, 'model'),\n",
              "        W2: PartitionSpec(None, 'model', None),\n",
              "    },\n",
              "}), nu=FrozenDict({\n",
              "    ScanDotReluDot_0: {\n",
              "        W1: PartitionSpec(None, None, 'model'),\n",
              "        W2: PartitionSpec(None, 'model', None),\n",
              "    },\n",
              "})), EmptyState()))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply `pjit` to complie the code\n",
        "\n",
        "이제 `jax.jit`와 비슷한 방식으로 `init_fn`에 JAX `pjit`을 적용할 수 있지만, 두 개의 추가 인수인 `in_axis_resources`와 `out_axis_resources`를 추가할 수 있습니다.\n",
        "\n",
        "`pjit`ted 함수를 실행할 때 `with mesh:` 컨텍스트를 추가해야 장치에 데이터를 올바르게 할당하기 위해 `mesh`(`jax.sharding.Mesh`의 인스턴스)를 참조할 수 있습니다."
      ],
      "metadata": {
        "id": "Z2pWLx4SYvOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pjit_init_fn = pjit(init_fn,\n",
        "                    static_argnums=(2, 3),\n",
        "                    in_axis_resources=(PartitionSpec(None), x_spec),  # PRNG key and x\n",
        "                    out_axis_resources=state_spec\n",
        "                    )\n",
        "with mesh:\n",
        "  initialized_state = pjit_init_fn(k, x, model, optimizer)\n",
        "jax.tree_map(jnp.shape, initialized_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdIWB22FZtJC",
        "outputId": "dd3a85c5-1de2-4a86-a164-d84d12717094"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainState(step=(), apply_fn=<bound method Module.apply of MLP(\n",
              "    # attributes\n",
              "    num_layers = 4\n",
              "    depth = 1024\n",
              "    use_scan = True\n",
              ")>, params=FrozenDict({\n",
              "    ScanDotReluDot_0: {\n",
              "        W1: Partitioned(value=(4, 1024, 1024), names=(None, None, 'model'), mesh=None),\n",
              "        W2: Partitioned(value=(4, 1024, 1024), names=(None, 'model', None), mesh=None),\n",
              "    },\n",
              "}), tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7f0c8c2831c0>, update=<function chain.<locals>.update_fn at 0x7f0c8c283370>), opt_state=(ScaleByAdamState(count=(), mu=FrozenDict({\n",
              "    ScanDotReluDot_0: {\n",
              "        W1: Partitioned(value=(4, 1024, 1024), names=(None, None, 'model'), mesh=None),\n",
              "        W2: Partitioned(value=(4, 1024, 1024), names=(None, 'model', None), mesh=None),\n",
              "    },\n",
              "}), nu=FrozenDict({\n",
              "    ScanDotReluDot_0: {\n",
              "        W1: Partitioned(value=(4, 1024, 1024), names=(None, None, 'model'), mesh=None),\n",
              "        W2: Partitioned(value=(4, 1024, 1024), names=(None, 'model', None), mesh=None),\n",
              "    },\n",
              "})), EmptyState()))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect the Module output\n",
        "\n",
        "`initialized_state`의 출력에서 `params` `W1`과 `W2`는 `flax.linen.Partitioned` 유형입니다. 이것은 Flax가 관련된 메타데이터를 기록할 수 있도록 실제 `jax.Array`를 감싸는 래퍼입니다. `.value`를 추가하거나 `.unbox()`를 실행하여 원시 `jax.Array`에 액세스할 수 있습니다.\n",
        "\n",
        "또한 JAX 배열의 기본 `jax.sharding`을 확인하면 분할 방식에 대한 힌트를 얻을 수 있습니다."
      ],
      "metadata": {
        "id": "ljx4iotVZvAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(initialized_state.params['ScanDotReluDot_0']['W1']))\n",
        "print(type(initialized_state.params['ScanDotReluDot_0']['W1'].value))\n",
        "print(initialized_state.params['ScanDotReluDot_0']['W1'].value.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mbZlQ9MaWpv",
        "outputId": "5bbf5213-59af-4a41-e3a8-b182e553b58e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'flax.core.meta.Partitioned'>\n",
            "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
            "(4, 1024, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(initialized_state.params['ScanDotReluDot_0']['W1'].value.sharding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY01496-aeck",
        "outputId": "8bd53768-5f75-4615-cb07-2482d592f81b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GSPMDSharding({devices=[1,1,4,2]0,4,1,5,2,6,3,7 last_tile_dim_replicate})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`jax.tree_map`을 사용하면 JAX 배열의 딕셔너리와 동일한 방식으로 박스형 매개변수 딕셔너리에 대해 대량 계산을 수행할 수 있습니다."
      ],
      "metadata": {
        "id": "RT-bZ_IOant6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff = jax.tree_map(\n",
        "    lambda a, b: a - b, \n",
        "    initialized_state.params['ScanDotReluDot_0'], initialized_state.params['ScanDotReluDot_0'])\n",
        "print(jax.tree_map(jnp.shape, diff))\n",
        "diff_array = diff['W1'].unbox()\n",
        "print(type(diff_array))\n",
        "print(diff_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxwAKpVIa5yq",
        "outputId": "ca80a5a1-9272-47f7-b3df-57296c7c7a57"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FrozenDict({\n",
            "    W1: Partitioned(value=(4, 1024, 1024), names=(None, None, 'model'), mesh=None),\n",
            "    W2: Partitioned(value=(4, 1024, 1024), names=(None, 'model', None), mesh=None),\n",
            "})\n",
            "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
            "(4, 1024, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply `pjit` to the train step and inference\n",
        "\n",
        "이제 `pjit` 트레이닝 단계를 생성합니다"
      ],
      "metadata": {
        "id": "dflYRuU4a78x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(state, x):\n",
        "  # A fake loss function.\n",
        "  def loss_unrolled(params):\n",
        "    y = model.apply({'params': params}, x)\n",
        "    return y.sum()\n",
        "  grad_fn = jax.grad(loss_unrolled)\n",
        "  grads = grad_fn(state.params)\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  return state\n",
        "\n",
        "pjit_step_fn = pjit(train_step,\n",
        "                    in_axis_resources=(state_spec, x_spec),  # input annotations\n",
        "                    out_axis_resources=state_spec,           # output annotations\n",
        "                    )\n",
        "with mesh:\n",
        "  new_state = pjit_step_fn(initialized_state, x)"
      ],
      "metadata": {
        "id": "8YJTAbN8bdDs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "추론에 `pjit`을 적용합니다. `jax.jit`와 유사하게 `@functools.partial(pjit, ...)`과 같은 데코레이터를 사용하여 함수를 직접 컴파일할 수 있습니다."
      ],
      "metadata": {
        "id": "KiBk7d01bhCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@functools.partial(pjit, in_axis_resources=(state_spec, x_spec), out_axis_resources=x_spec)\n",
        "def pjit_apply_fn(state, x):\n",
        "  return state.apply_fn({'params': state.params}, x)\n",
        "\n",
        "with mesh:\n",
        "  y = pjit_apply_fn(new_state, x)\n",
        "print(type(y))\n",
        "print(y.dtype)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbdMt8vrbeT-",
        "outputId": "f6ca5f85-26e9-49c0-9ff0-bbd50ca794b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
            "float32\n",
            "(8, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Profiling\n",
        "\n",
        "TPU 팟 또는 팟 슬라이스에서 실행 중인 경우, 아래에 정의된 대로 사용자 정의 block_all 유틸리티 함수를 사용하여 성능을 측정할 수 있습니다"
      ],
      "metadata": {
        "id": "NPNSj71aboWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "def block_all(xs):\n",
        "  jax.tree_map(lambda x: x.block_until_ready(), xs)\n",
        "  return xs\n",
        "\n",
        "with mesh:\n",
        "  new_state = block_all(pjit_step_fn(initialized_state, x))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj_jdJ61cFmK",
        "outputId": "026afdac-f895-4d22-991a-ecc1f7f1ff35"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "621 ms ± 89.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logical axis annotation\n",
        "\n",
        "JAX auto SPMD는 사용자가 최적의 샤딩 레이아웃을 찾기 위해 다양한 샤딩 레이아웃을 탐색하도록 권장합니다. 이를 위해 Flax에서는 실제로 `'data'`, `'model'`과 같은 장치 메시 축 이름뿐만 아니라 더 설명적인 축 이름으로 모든 데이터의 차원에 주석을 달 수 있습니다.\n",
        "\n",
        "아래의 `LogicalDotReluDot` 및 `LogicalMLP` 모듈 정의는 다음을 제외하고는 앞서 생성한 모듈과 유사합니다:\n",
        "\n",
        "1. 모든 축에는 `'embed'`, `'hidden'`, `'batch'` 및 `'layer'`와 같은 보다 구체적이고 의미 있는 이름이 주석으로 지정되어 있습니다. 이러한 이름을 Flax에서는 논리적 축 이름이라고 합니다. 이러한 이름을 사용하면 모델 정의 내부의 차원 변경 사항을 더 읽기 쉽게 만들 수 있습니다.\n",
        "\n",
        "2. `flax.linen.spmd.with_logical_partitioning`은 `flax.linen.with_partitioning`을 대체하고, `flax.linen.spmd.with_logical_constraint`는 `pjit.with_sharding_constraint`를 대체하여 논리적 축 이름을 인식할 수 있습니다."
      ],
      "metadata": {
        "id": "PeFmZiRLcHQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogicalDotReluDot(nn.Module):\n",
        "  depth: int\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    W1 = self.param(\n",
        "        'W1', \n",
        "        spmd.with_logical_partitioning(nn.initializers.xavier_normal(), ('embed', 'hidden')),\n",
        "        (x.shape[-1], self.depth)) \n",
        "\n",
        "    y = jax.nn.relu(jnp.dot(x, W1))\n",
        "    # Force a local sharding annotation.\n",
        "    y = spmd.with_logical_constraint(y, ('batch', 'hidden'))\n",
        "\n",
        "    W2 = self.param(\n",
        "        'W2', \n",
        "        spmd.with_logical_partitioning(nn.initializers.xavier_normal(), ('hidden', 'embed')),\n",
        "        (self.depth, x.shape[-1]))\n",
        "\n",
        "    z = jnp.dot(y, W2)\n",
        "    # Force a local sharding annotation.\n",
        "    z = spmd.with_logical_constraint(z, ('batch', 'embed'))\n",
        "    return z, None\n",
        "\n",
        "class LogicalMLP(nn.Module):\n",
        "  num_layers: int\n",
        "  depth: int\n",
        "  use_scan: bool\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    if self.use_scan:\n",
        "      x, _ = nn.scan(LogicalDotReluDot, length=self.num_layers, \n",
        "                    variable_axes={\"params\": 0},\n",
        "                    split_rngs={\"params\": True},\n",
        "                    metadata_params={nn.PARTITION_NAME: 'layer'}\n",
        "                    )(self.depth)(x)\n",
        "    else:\n",
        "      for i in range(self.num_layers):\n",
        "        x, _ = DotReluDot(self.depth)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "k81ofxzEc4mw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`LogicalMLP` 모델 정의는 논리적 축 이름을 가진 `PartitionSpec` 집합을 생성합니다.\n",
        "\n",
        "이전 단계를 반복합니다. 모델을 인스턴스화하고, `init_fn`을 추상적으로 평가한 다음, `flax.linen.get_partition_spec`을 사용하여 `PartitionSpec`을 자동으로 생성합니다:"
      ],
      "metadata": {
        "id": "9Tj88UVHc6WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logical_model = LogicalMLP(LAYERS, DEPTH, USE_SCAN)\n",
        "logical_abstract_variables = jax.eval_shape(\n",
        "    functools.partial(init_fn, model=logical_model, optimizer=optimizer), k, x)\n",
        "logical_output_spec = nn.get_partition_spec(logical_abstract_variables)\n",
        "logical_output_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jrpTw6JdH-Y",
        "outputId": "a88f5a4e-16b4-4e62-92c2-167c34aa2f50"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainState(step=PartitionSpec(), apply_fn=<bound method Module.apply of LogicalMLP(\n",
              "    # attributes\n",
              "    num_layers = 4\n",
              "    depth = 1024\n",
              "    use_scan = True\n",
              ")>, params=FrozenDict({\n",
              "    ScanLogicalDotReluDot_0: {\n",
              "        W1: PartitionSpec('layer', 'embed', 'hidden'),\n",
              "        W2: PartitionSpec('layer', 'hidden', 'embed'),\n",
              "    },\n",
              "}), tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7f0c8c2831c0>, update=<function chain.<locals>.update_fn at 0x7f0c8c283370>), opt_state=(ScaleByAdamState(count=PartitionSpec(), mu=FrozenDict({\n",
              "    ScanLogicalDotReluDot_0: {\n",
              "        W1: PartitionSpec('layer', 'embed', 'hidden'),\n",
              "        W2: PartitionSpec('layer', 'hidden', 'embed'),\n",
              "    },\n",
              "}), nu=FrozenDict({\n",
              "    ScanLogicalDotReluDot_0: {\n",
              "        W1: PartitionSpec('layer', 'embed', 'hidden'),\n",
              "        W2: PartitionSpec('layer', 'hidden', 'embed'),\n",
              "    },\n",
              "})), EmptyState()))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "장치 메시가 모델을 올바르게 가져올 수 있도록 하려면 이러한 논리적 축 이름 중 장치 축 `'data'` 또는 `'model'`에 매핑되는 이름을 결정해야 합니다. \n",
        "\n",
        "이 규칙은 (`logical_axis_name`, `device_axis_name`) 튜플의 목록이며, `jax.linen.spmd.logical_to_mesh`는 이를 `pjit`가 허용하는 사양으로 변환합니다.\n",
        "\n",
        "이를 통해 모델 정의를 수정하지 않고도 규칙을 변경하고 새로운 파티션 레이아웃을 시도해 볼 수 있습니다."
      ],
      "metadata": {
        "id": "9KFkASqXdM69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unspecified rule means unsharded by default, so no need to specify `('embed', None)` and `('layer', None)`.\n",
        "rules = (('batch', 'data'),\n",
        "         ('hidden', 'model'))\n",
        "\n",
        "logical_state_spec = spmd.logical_to_mesh(logical_output_spec, rules)\n",
        "logical_state_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6v-m6mCdfqL",
        "outputId": "bf52546c-bc8d-428b-86bf-038849d334c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainState(step=PartitionSpec(), apply_fn=<bound method Module.apply of LogicalMLP(\n",
              "    # attributes\n",
              "    num_layers = 4\n",
              "    depth = 1024\n",
              "    use_scan = True\n",
              ")>, params=FrozenDict({\n",
              "    ScanLogicalDotReluDot_0: {\n",
              "        W1: PartitionSpec(None, None, 'model'),\n",
              "        W2: PartitionSpec(None, 'model', None),\n",
              "    },\n",
              "}), tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7f0c8c2831c0>, update=<function chain.<locals>.update_fn at 0x7f0c8c283370>), opt_state=(ScaleByAdamState(count=PartitionSpec(), mu=FrozenDict({\n",
              "    ScanLogicalDotReluDot_0: {\n",
              "        W1: PartitionSpec(None, None, 'model'),\n",
              "        W2: PartitionSpec(None, 'model', None),\n",
              "    },\n",
              "}), nu=FrozenDict({\n",
              "    ScanLogicalDotReluDot_0: {\n",
              "        W1: PartitionSpec(None, None, 'model'),\n",
              "        W2: PartitionSpec(None, 'model', None),\n",
              "    },\n",
              "})), EmptyState()))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기의 `logical_state_spec`이 이전(\"non-logical\") 예제의 `state_spec`과 동일한 내용을 가지고 있는지 확인할 수 있습니다. 이것은 분할된 함수를 생성할 때 지정한 `out_axis_resources`가 됩니다."
      ],
      "metadata": {
        "id": "U99_nTQ-dhHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_spec.params['ScanDotReluDot_0'] == logical_state_spec.params['ScanLogicalDotReluDot_0']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbUn3ePYd2cs",
        "outputId": "36e5e274-39f3-422e-c8a5-15090a2bdd20"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logical_pjit_init_fn = pjit(init_fn,\n",
        "                            static_argnums=(2, 3),\n",
        "                            in_axis_resources=(PartitionSpec(None), x_spec),  # RNG key and x\n",
        "                            out_axis_resources=logical_state_spec\n",
        "                            )\n",
        "with mesh:\n",
        "  logical_initialized_state = logical_pjit_init_fn(k, x, logical_model, optimizer)\n",
        "jax.tree_map(jnp.shape, logical_initialized_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fMTyiOxd4m3",
        "outputId": "327d2ce7-9b26-4284-c285-a2fcc4f2d89b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainState(step=(), apply_fn=<bound method Module.apply of LogicalMLP(\n",
              "    # attributes\n",
              "    num_layers = 4\n",
              "    depth = 1024\n",
              "    use_scan = True\n",
              ")>, params=FrozenDict({\n",
              "    ScanLogicalDotReluDot_0: {\n",
              "        W1: LogicallyPartitioned(value=(4, 1024, 1024), names=('layer', 'embed', 'hidden'), mesh=None, rules=None),\n",
              "        W2: LogicallyPartitioned(value=(4, 1024, 1024), names=('layer', 'hidden', 'embed'), mesh=None, rules=None),\n",
              "    },\n",
              "}), tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7f0c8c2831c0>, update=<function chain.<locals>.update_fn at 0x7f0c8c283370>), opt_state=(ScaleByAdamState(count=(), mu=FrozenDict({\n",
              "    ScanLogicalDotReluDot_0: {\n",
              "        W1: LogicallyPartitioned(value=(4, 1024, 1024), names=('layer', 'embed', 'hidden'), mesh=None, rules=None),\n",
              "        W2: LogicallyPartitioned(value=(4, 1024, 1024), names=('layer', 'hidden', 'embed'), mesh=None, rules=None),\n",
              "    },\n",
              "}), nu=FrozenDict({\n",
              "    ScanLogicalDotReluDot_0: {\n",
              "        W1: LogicallyPartitioned(value=(4, 1024, 1024), names=('layer', 'embed', 'hidden'), mesh=None, rules=None),\n",
              "        W2: LogicallyPartitioned(value=(4, 1024, 1024), names=('layer', 'hidden', 'embed'), mesh=None, rules=None),\n",
              "    },\n",
              "})), EmptyState()))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When to use device axis / logical axis\n",
        "\n",
        "디바이스 또는 논리적 축을 사용할 시기는 모델의 파티셔닝을 얼마나 제어할 것인지에 따라 달라집니다.\n",
        "\n",
        "매우 단순한 모델을 원하거나 파티셔닝 방식에 자신이 있는 경우, 디바이스 메시 축으로 정의하면 논리적 네이밍을 디바이스 네이밍으로 다시 변환하는 몇 줄의 추가 코드를 절약할 수 있습니다.\n",
        "\n",
        "반면에 논리적 이름 지정 도우미는 다양한 샤딩 레이아웃을 탐색하는 데 유용합니다. 여러 가지를 실험해보고 모델에 가장 적합한 파티션 레이아웃을 찾으려는 경우 이 기능을 사용하세요.\n",
        "\n",
        "정말 고급 사용 사례에서는 활성화 차원 이름에 매개변수 차원 이름과 다르게 주석을 달아야 하는 더 복잡한 샤딩 패턴이 있을 수 있습니다. 수동 메시 할당을 보다 세밀하게 제어하려는 경우 디바이스 축 이름을 직접 사용하는 것이 더 유용할 수 있습니다."
      ],
      "metadata": {
        "id": "ZRujr7H5eCI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the data\n",
        "\n",
        "Save and load checkpoints guide - Multi-host/multi-process checkpointing에 표시된 대로 flax.training.checkpoints를 사용하여 교차 장치 배열을 저장할 수 있습니다. 이는 다중 호스트 환경(예: TPU 팟)에서 실행하는 경우 특히 필요합니다.\n",
        "\n",
        "어레이를 원하는 파티션으로 복원하려면 각 JAX 어레이에 대해 동일한 구조를 가지며 원하는 `PartitionSpec`이 있는 샘플 대상 파이트리를 제공해야 한다는 점에 유의하세요. 배열을 복원하는 데 사용하는 `PartitionSpec`은 배열을 저장하는 데 사용한 것과 반드시 동일할 필요는 없습니다."
      ],
      "metadata": {
        "id": "oZn2kbH2d-PH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e0cfxLZrehNc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}