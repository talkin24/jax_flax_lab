{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJd3dhiyld0gaH+K2JNlgE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talkin24/jaxflax_lab/blob/main/Unet_jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3-a6P7-SDblc"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax import lax, random, numpy as jnp\n",
        "\n",
        "import flax\n",
        "from flax.core import freeze, unfreeze\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "\n",
        "import optax\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import functools\n",
        "from typing import Any, Callable, Sequence, Optional\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UnetConvBlock(nn.Module):\n",
        "  out_dim: int\n",
        "\n",
        "  # Conv Parameters\n",
        "  kernel_size: tuple[int, int] = (3, 3)\n",
        "  strides: int = 1\n",
        "  padding: int = 0\n",
        "\n",
        "  # BatchNorm Parameters\n",
        "  use_running_average: bool = False\n",
        "  momentum: float = 0.9\n",
        "  epsilon: float = 1e-5\n",
        "  dtype: jnp.dtype = jnp.float32\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=self.out_dim, kernel_size=self.kernel_size, strides=self.strides, padding=self.padding)(x)\n",
        "    x = nn.BatchNorm(use_running_average=self.use_running_average, momentum=self.momentum, epsilon = self.epsilon, dtype = self.dtype)(x) \n",
        "    x = nn.relu(x)\n",
        "    x = nn.Conv(features=self.out_dim, kernel_size=self.kernel_size, strides=self.strides, padding=self.padding)(x)\n",
        "    x = nn.BatchNorm(use_running_average=self.use_running_average, momentum=self.momentum, epsilon = self.epsilon, dtype = self.dtype)(x) \n",
        "    x = nn.relu(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Xe-Z3FyTKfHC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConvBR(nn.Module):\n",
        "  out_dim: int\n",
        "\n",
        "  # Conv Parameters\n",
        "  kernel_size: tuple[int, int] = (3, 3)\n",
        "  strides: int = 1\n",
        "  padding: int = 0\n",
        "  \n",
        "  # BatchNorm Parameters\n",
        "  use_running_average: bool = False\n",
        "  momentum: float = 0.9\n",
        "  epsilon: float = 1e-5\n",
        "  dtype: jnp.dtype = jnp.float32\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=self.out_dim, kernel_size=self.kernel_size, strides=self.strides, padding=self.padding)(x)\n",
        "    x = nn.BatchNorm(use_running_average=self.use_running_average, momentum=self.momentum, epsilon = self.epsilon, dtype = self.dtype)(x) \n",
        "    x = nn.relu(x)\n",
        "    x = nn.Conv(features=self.out_dim, kernel_size=self.kernel_size, strides=self.strides, padding=self.padding)(x)\n",
        "    x = nn.BatchNorm(use_running_average=self.use_running_average, momentum=self.momentum, epsilon = self.epsilon, dtype = self.dtype)(x) \n",
        "    x = nn.relu(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "  out_dim: int\n",
        "  \n",
        "  # max_pool Parameters\n",
        "  window_shape: tuple[int, int] = (2, 2)\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.max_pool(x, window_shape=self.window_shape)\n",
        "    x = DoubleConvBR(self.out_dim)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "  out_dim: int\n",
        "  \n",
        "  # ConvTranspose Parameters\n",
        "  kernel_size: tuple[int, int] = (2, 2)\n",
        "  strides: tuple[int, int] = (2, 2)\n",
        "  padding: int = 0\n",
        " \n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.ConvTranspose(features=self.out_dim * 2, kernel_size=self.kernel_size, strides=self.strides, padding=self.padding)(x)\n",
        "    x = DoubleConvBR(self.out_dim)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Unet(nn.Module):\n",
        "  feature_scale: int = 4\n",
        "  n_classes: int = 21\n",
        "  window_shape: tuple[int, int] = (2, 2)\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "\n",
        "  # Contracting path\n",
        "    x = DoubleConvBR(64)(x)\n",
        "    x = Down(128)(x)\n",
        "    x = Down(256)(x)\n",
        "    x = Down(512)(x)\n",
        "    x = Down(1024)(x)\n",
        "\n",
        "  # Expansive path\n",
        "    x = Up(512)(x)\n",
        "    x = Up(256)(x)\n",
        "    x = Up(128)(x)\n",
        "    x = Up(64)(x)\n",
        "    \n",
        "    x = nn.Dense(2)(x)\n"
      ],
      "metadata": {
        "id": "4O2auIoeDhAy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet = Unet()\n",
        "print(unet.tabulate(jax.random.PRNGKey(0), jnp.ones((3, 572, 572))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_962GH2YTXYa",
        "outputId": "2156ddb0-e592-4bbe-c34a-1f71dd339452"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[3m                                  Unet Summary                                  \u001b[0m\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mbatch_stats\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams    \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
            "│            │ Unet       │ \u001b[2mfloat32\u001b[0m[3… │ None       │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ DoubleCon… │ DoubleCon… │ \u001b[2mfloat32\u001b[0m[3… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ DoubleCon… │ Conv       │ \u001b[2mfloat32\u001b[0m[3… │ \u001b[2mfloat32\u001b[0m[1… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m329,536 \u001b[0m   │\n",
            "│            │            │            │            │             │ \u001b[1;2m(1.3 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ DoubleCon… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[1… │ \u001b[2mfloat32\u001b[0m[1… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 \u001b[0m  │\n",
            "│            │            │            │            │             │ \u001b[1;2mB)\u001b[0m         │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ DoubleCon… │ Conv       │ \u001b[2mfloat32\u001b[0m[1… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m36,928 \u001b[0m    │\n",
            "│            │            │            │            │             │ \u001b[1;2m(147.7 KB)\u001b[0m │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ DoubleCon… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 \u001b[0m  │\n",
            "│            │            │            │            │             │ \u001b[1;2mB)\u001b[0m         │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_0     │ Down       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_0/Do… │ DoubleCon… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_0/Do… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m73,856 \u001b[0m    │\n",
            "│            │            │            │            │             │ \u001b[1;2m(295.4 KB)\u001b[0m │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_0/Do… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[12… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[12… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 \u001b[0m   │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 \u001b[0m  │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_0/Do… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m147,584 \u001b[0m   │\n",
            "│            │            │            │            │             │ \u001b[1;2m(590.3 KB)\u001b[0m │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_0/Do… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[12… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[12… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 \u001b[0m   │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 \u001b[0m  │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_1     │ Down       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_1/Do… │ DoubleCon… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_1/Do… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m295,168 \u001b[0m   │\n",
            "│            │            │            │            │             │ \u001b[1;2m(1.2 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_1/Do… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[25… │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[25… │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m512 \u001b[0m\u001b[1;2m(2.0 \u001b[0m   │ \u001b[1m512 \u001b[0m\u001b[1;2m(2.0 \u001b[0m  │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_1/Do… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m590,080 \u001b[0m   │\n",
            "│            │            │            │            │             │ \u001b[1;2m(2.4 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_1/Do… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[25… │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[25… │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m512 \u001b[0m\u001b[1;2m(2.0 \u001b[0m   │ \u001b[1m512 \u001b[0m\u001b[1;2m(2.0 \u001b[0m  │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_2     │ Down       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_2/Do… │ DoubleCon… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_2/Do… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m1,180,160 \u001b[0m │\n",
            "│            │            │            │            │             │ \u001b[1;2m(4.7 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_2/Do… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[51… │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[51… │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 \u001b[0m │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1\u001b[0m │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_2/Do… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m2,359,808 \u001b[0m │\n",
            "│            │            │            │            │             │ \u001b[1;2m(9.4 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_2/Do… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[51… │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[51… │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 \u001b[0m │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1\u001b[0m │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_3     │ Down       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_3/Do… │ DoubleCon… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_3/Do… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m4,719,616 \u001b[0m │\n",
            "│            │            │            │            │             │ \u001b[1;2m(18.9 MB)\u001b[0m  │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_3/Do… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[10… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[10… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m2,048 \u001b[0m\u001b[1;2m(8.2 \u001b[0m │ \u001b[1m2,048 \u001b[0m\u001b[1;2m(8.2\u001b[0m │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_3/Do… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m9,438,208 \u001b[0m │\n",
            "│            │            │            │            │             │ \u001b[1;2m(37.8 MB)\u001b[0m  │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Down_3/Do… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[10… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[10… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m2,048 \u001b[0m\u001b[1;2m(8.2 \u001b[0m │ \u001b[1m2,048 \u001b[0m\u001b[1;2m(8.2\u001b[0m │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_0       │ Up         │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_0/Conv… │ ConvTrans… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m4,195,328 \u001b[0m │\n",
            "│            │            │            │            │             │ \u001b[1;2m(16.8 MB)\u001b[0m  │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_0/Doub… │ DoubleCon… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_0/Doub… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m4,719,104 \u001b[0m │\n",
            "│            │            │            │            │             │ \u001b[1;2m(18.9 MB)\u001b[0m  │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_0/Doub… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[51… │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[51… │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 \u001b[0m │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1\u001b[0m │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_0/Doub… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m2,359,808 \u001b[0m │\n",
            "│            │            │            │            │             │ \u001b[1;2m(9.4 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_0/Doub… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[51… │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[51… │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 \u001b[0m │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1\u001b[0m │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_1       │ Up         │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_1/Conv… │ ConvTrans… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[5… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m1,049,088 \u001b[0m │\n",
            "│            │            │            │            │             │ \u001b[1;2m(4.2 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_1/Doub… │ DoubleCon… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_1/Doub… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m1,179,904 \u001b[0m │\n",
            "│            │            │            │            │             │ \u001b[1;2m(4.7 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_1/Doub… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[25… │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[25… │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m512 \u001b[0m\u001b[1;2m(2.0 \u001b[0m   │ \u001b[1m512 \u001b[0m\u001b[1;2m(2.0 \u001b[0m  │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_1/Doub… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m590,080 \u001b[0m   │\n",
            "│            │            │            │            │             │ \u001b[1;2m(2.4 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_1/Doub… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[25… │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[25… │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m512 \u001b[0m\u001b[1;2m(2.0 \u001b[0m   │ \u001b[1m512 \u001b[0m\u001b[1;2m(2.0 \u001b[0m  │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_2       │ Up         │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_2/Conv… │ ConvTrans… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m262,400 \u001b[0m   │\n",
            "│            │            │            │            │             │ \u001b[1;2m(1.0 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_2/Doub… │ DoubleCon… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_2/Doub… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m295,040 \u001b[0m   │\n",
            "│            │            │            │            │             │ \u001b[1;2m(1.2 MB)\u001b[0m   │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_2/Doub… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[12… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[12… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 \u001b[0m   │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 \u001b[0m  │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_2/Doub… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m147,584 \u001b[0m   │\n",
            "│            │            │            │            │             │ \u001b[1;2m(590.3 KB)\u001b[0m │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_2/Doub… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[12… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[12… │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 \u001b[0m   │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 \u001b[0m  │\n",
            "│            │            │            │            │ \u001b[1;2mKB)\u001b[0m         │ \u001b[1;2mKB)\u001b[0m        │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_3       │ Up         │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_3/Conv… │ ConvTrans… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[1… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[2… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m65,664 \u001b[0m    │\n",
            "│            │            │            │            │             │ \u001b[1;2m(262.7 KB)\u001b[0m │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_3/Doub… │ DoubleCon… │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │            │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_3/Doub… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m73,792 \u001b[0m    │\n",
            "│            │            │            │            │             │ \u001b[1;2m(295.2 KB)\u001b[0m │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_3/Doub… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 \u001b[0m  │\n",
            "│            │            │            │            │             │ \u001b[1;2mB)\u001b[0m         │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_3/Doub… │ Conv       │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[3… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m36,928 \u001b[0m    │\n",
            "│            │            │            │            │             │ \u001b[1;2m(147.7 KB)\u001b[0m │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Up_3/Doub… │ BatchNorm  │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │ mean:       │ bias:      │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │ var:        │ scale:     │\n",
            "│            │            │            │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 \u001b[0m  │\n",
            "│            │            │            │            │             │ \u001b[1;2mB)\u001b[0m         │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Dense_0    │ Dense      │ \u001b[2mfloat32\u001b[0m[0… │ \u001b[2mfloat32\u001b[0m[0… │             │ bias:      │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[2] │\n",
            "│            │            │            │            │             │ kernel:    │\n",
            "│            │            │            │            │             │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │            │            │            │             │            │\n",
            "│            │            │            │            │             │ \u001b[1m130 \u001b[0m\u001b[1;2m(520 \u001b[0m  │\n",
            "│            │            │            │            │             │ \u001b[1;2mB)\u001b[0m         │\n",
            "├────────────┼────────────┼────────────┼────────────┼─────────────┼────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m     Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m11,776     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m34,157,570\u001b[0m\u001b[1m \u001b[0m│\n",
            "│\u001b[1m            \u001b[0m│\u001b[1m            \u001b[0m│\u001b[1m            \u001b[0m│\u001b[1m            \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2m(47.1 KB)\u001b[0m\u001b[1m  \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2m(136.6 MB)\u001b[0m\u001b[1m \u001b[0m│\n",
            "└────────────┴────────────┴────────────┴────────────┴─────────────┴────────────┘\n",
            "\u001b[1m                                                                                \u001b[0m\n",
            "\u001b[1m                    Total Parameters: 34,169,346 \u001b[0m\u001b[1;2m(136.7 MB)\u001b[0m\u001b[1m                     \u001b[0m\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "QkDX7pMVTgzM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_transform(x):\n",
        "    # A couple of modifications here compared to tutorial #3 since we're using a CNN\n",
        "    # Input: (28, 28) uint8 [0, 255] torch.Tensor, Output: (28, 28, 1) float32 [0, 1] np array\n",
        "    return np.expand_dims(np.array(x, dtype=np.float32), axis=2) / 255.\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"Provides us with batches of numpy arrays and not PyTorch's tensors.\"\"\"\n",
        "    transposed_data = list(zip(*batch))\n",
        "\n",
        "    labels = np.array(transposed_data[1])\n",
        "    imgs = np.stack(transposed_data[0])\n",
        "\n",
        "    return imgs, labels\n",
        "\n",
        "mnist_img_size = (28, 28, 1)\n",
        "batch_size = 128\n",
        "\n",
        "train_dataset = MNIST(root='train_mnist', train=True, download=True, transform=custom_transform)\n",
        "test_dataset = MNIST(root='test_mnist', train=False, download=True, transform=custom_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn, drop_last=True)\n",
        "\n",
        "# optimization - loading the whole dataset into memory\n",
        "train_images = jnp.array(train_dataset.data)\n",
        "train_lbls = jnp.array(train_dataset.targets)\n",
        "\n",
        "# np.expand_dims is to convert shape from (10000, 28, 28) -> (10000, 28, 28, 1)\n",
        "# We don't have to do this for training images because custom_transform does it for us.\n",
        "test_images = np.expand_dims(jnp.array(test_dataset.data), axis=3)\n",
        "test_lbls = jnp.array(test_dataset.targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nJ9KCX2j3xB",
        "outputId": "7ea61dce-891a-4afc-d34f-80acf9471dea"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to train_mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 74040185.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting train_mnist/MNIST/raw/train-images-idx3-ubyte.gz to train_mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to train_mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 9027177.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting train_mnist/MNIST/raw/train-labels-idx1-ubyte.gz to train_mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to train_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 21631087.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting train_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to train_mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to train_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 11594965.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting train_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to train_mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to test_mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 80717467.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting test_mnist/MNIST/raw/train-images-idx3-ubyte.gz to test_mnist/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to test_mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 37203837.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting test_mnist/MNIST/raw/train-labels-idx1-ubyte.gz to test_mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to test_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 22270676.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting test_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to test_mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to test_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 9749502.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting test_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to test_mnist/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a single image\n",
        "imgs, lbls = next(iter(test_loader))\n",
        "img = imgs[0].reshape(mnist_img_size)[:, :, 0]\n",
        "gt_lbl = lbls[0]\n",
        "\n",
        "print(gt_lbl)\n",
        "plt.imshow(img); plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "olisdFDAj-K8",
        "outputId": "05bef29c-9155-46be-d390-6a82b659f9e6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(state, imgs, gt_labels):\n",
        "    def loss_fn(params):\n",
        "        logits = Unet().apply({'params': params}, imgs)\n",
        "        one_hot_gt_labels = jax.nn.one_hot(gt_labels, num_classes=10)\n",
        "        loss = -jnp.mean(jnp.sum(one_hot_gt_labels * logits, axis=-1))\n",
        "        return loss, logits\n",
        "  \n",
        "    (_, logits), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
        "    state = state.apply_gradients(grads=grads)  # this is the whole update now! concise!\n",
        "    metrics = compute_metrics(logits=logits, gt_labels=gt_labels)  # duplicating loss calculation but it's a bit cleaner\n",
        "    return state, metrics\n",
        "\n",
        "@jax.jit\n",
        "def eval_step(state, imgs, gt_labels):\n",
        "    logits = Unet().apply({'params': state.params}, imgs)\n",
        "    return compute_metrics(logits=logits, gt_labels=gt_labels)"
      ],
      "metadata": {
        "id": "bX502O9nkFmk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(state, dataloader, epoch):\n",
        "    \"\"\"Train for 1 epoch on the training set.\"\"\"\n",
        "    batch_metrics = []\n",
        "    for cnt, (imgs, labels) in enumerate(dataloader):\n",
        "        state, metrics = train_step(state, imgs, labels)\n",
        "        batch_metrics.append(metrics)\n",
        "\n",
        "    # Aggregate the metrics\n",
        "    batch_metrics_np = jax.device_get(batch_metrics)  # pull from the accelerator onto host (CPU)\n",
        "    epoch_metrics_np = {\n",
        "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
        "        for k in batch_metrics_np[0]\n",
        "    }\n",
        "\n",
        "    return state, epoch_metrics_np\n",
        "\n",
        "def evaluate_model(state, test_imgs, test_lbls):\n",
        "    \"\"\"Evaluate on the validation set.\"\"\"\n",
        "    metrics = eval_step(state, test_imgs, test_lbls)\n",
        "    metrics = jax.device_get(metrics)  # pull from the accelerator onto host (CPU)\n",
        "    metrics = jax.tree_map(lambda x: x.item(), metrics)  # np.ndarray -> scalar\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "Y4H-udd4kNYL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This one will keep things nice and tidy compared to our previous examples\n",
        "def create_train_state(key, learning_rate, momentum):\n",
        "    unet = Unet()\n",
        "    params = unet.init(key, jnp.ones([1, *mnist_img_size]))['params']\n",
        "    sgd_opt = optax.sgd(learning_rate, momentum)\n",
        "    # TrainState is a simple built-in wrapper class that makes things a bit cleaner\n",
        "    return train_state.TrainState.create(apply_fn=unet.apply, params=params, tx=sgd_opt)\n",
        "\n",
        "def compute_metrics(*, logits, gt_labels):\n",
        "    one_hot_gt_labels = jax.nn.one_hot(gt_labels, num_classes=10)\n",
        "\n",
        "    loss = -jnp.mean(jnp.sum(one_hot_gt_labels * logits, axis=-1))\n",
        "    accuracy = jnp.mean(jnp.argmax(logits, -1) == gt_labels)\n",
        "\n",
        "    metrics = {\n",
        "        'loss': loss,\n",
        "        'accuracy': accuracy,\n",
        "    }\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "nOyHanxzkO_y"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally let's define the high-level training/val loops\n",
        "seed = 0  # needless to say these should be in a config or defined like flags\n",
        "learning_rate = 0.1\n",
        "momentum = 0.9\n",
        "num_epochs = 2\n",
        "batch_size = 32\n",
        "\n",
        "train_state = create_train_state(jax.random.PRNGKey(seed), learning_rate, momentum)\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_state, train_metrics = train_one_epoch(train_state, train_loader, epoch)\n",
        "    print(f\"Train epoch: {epoch}, loss: {train_metrics['loss']}, accuracy: {train_metrics['accuracy'] * 100}\")\n",
        "\n",
        "    test_metrics = evaluate_model(train_state, test_images, test_lbls)\n",
        "    print(f\"Test epoch: {epoch}, loss: {test_metrics['loss']}, accuracy: {test_metrics['accuracy'] * 100}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "RiCYKjRDkQki",
        "outputId": "43eb8f35-d657-484e-e9f1-556ce7074a12"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ScopeCollectionNotFound",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mScopeCollectionNotFound\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-78e4f8736946>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train epoch: {epoch}, loss: {train_metrics['loss']}, accuracy: {train_metrics['accuracy'] * 100}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-f41d59039cde>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(state, dataloader, epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-014c12b18031>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(state, imgs, gt_labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this is the whole update now! concise!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgt_labels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# duplicating loss calculation but it's a bit cleaner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-014c12b18031>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mone_hot_gt_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_gt_labels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-9bca41e1a9e8>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;31m# Contracting path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoubleConvBR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-9bca41e1a9e8>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_running_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_running_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/flax/linen/normalization.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, use_running_average)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mfeature_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_axes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     ra_mean = self.variable('batch_stats', 'mean',\n\u001b[0m\u001b[1;32m    257\u001b[0m                             \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                             feature_shape)\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/flax/core/scope.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(self, col, name, init_fn, unbox, *init_args)\u001b[0m\n\u001b[1;32m    792\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mutable_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_collection_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScopeCollectionNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScopeVariableNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0minit_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mScopeCollectionNotFound\u001b[0m: Tried to access \"mean\" from collection \"batch_stats\" in \"/DoubleConvBR_0/BatchNorm_0\" but the collection is empty. (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeCollectionNotFound)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WegqjG5bkezD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}